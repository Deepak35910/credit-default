{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "credit_default_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdmpAKsL7dJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c7489f-2b5e-4eb4-c8d6-9e0ba1d045f5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pbPuCIK8OjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a798132c-6557-45e2-cfae-c9ca31cb138b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cI5gUZX7dJL"
      },
      "source": [
        "importing data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtvyB8jO7dJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7d3e1e-3c78-48a6-ddf6-e9d1663a1320"
      },
      "source": [
        "data = pd.read_csv(r'/content/gdrive/My Drive/Colab Notebooks/Loan_default/XYZCorp_LendingData.txt', sep=\"\\t\"\n",
        "                   ,header = 0)\n",
        "dummy=pd.DataFrame.copy(data) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (17,45,53) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8uvccLWb2rn",
        "outputId": "3d0885a9-3bc5-4b1a-aebf-dc2a9a8588d5"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(855969, 73)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lncrKk4-7dJW"
      },
      "source": [
        "displaying all column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c20Ho4Zk7dJY"
      },
      "source": [
        "pd.set_option('display.max_columns',None)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GYD_fYe7dJf"
      },
      "source": [
        "checking duplicate ids - no duplicate ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7EBozSf7dJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81fcdba-2afd-4fde-fff7-7ca7e8159a77"
      },
      "source": [
        "print(any(dummy['member_id'].duplicated()))                    \n",
        "print(any(dummy['id'].duplicated()))                     "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGQ-TE417dJm"
      },
      "source": [
        "dropping variables which are not required for modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojvdy9iJ7dJn"
      },
      "source": [
        "dummy=dummy.drop(['id','member_id','emp_title','desc','title','addr_state','zip_code'],axis=1) \n",
        "#dropping variable that are not  relevent in modelling"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7XlK2sy7dJr"
      },
      "source": [
        "policy_code is 1 for all - no variation<br>\n",
        "pymnt_plan is y just for 5 - no variation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgT4UJmE7dJs"
      },
      "source": [
        "dummy=dummy.drop(['pymnt_plan','policy_code'],axis=1) "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GIT60MM7dJx"
      },
      "source": [
        "Dropping grade variable as we already have sub grade [sub grade has more detailed info than grade]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gagsI--b7dJy"
      },
      "source": [
        "dummy=dummy.drop(['grade'],axis=1) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2W-frtF7dJ1"
      },
      "source": [
        "Dropping below variables as they have no  contribution to y=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdBNb8vo7dJ2"
      },
      "source": [
        "dummy=dummy.drop(['annual_inc_joint','dti_joint','verification_status_joint'],axis=1) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkghvW1i7dJ6"
      },
      "source": [
        "dummy=dummy.drop(['open_acc_6m','open_il_6m','open_il_12m','open_il_24m',\n",
        "                  'mths_since_rcnt_il','total_bal_il','il_util','open_rv_12m',\n",
        "                  'open_rv_24m','max_bal_bc','all_util','inq_fi','total_cu_tl',\n",
        "                  'inq_last_12m'],axis=1) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOU89sj07dKD"
      },
      "source": [
        "Dropping variables with too many missing value > 50%\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTwxqwRq7dKF"
      },
      "source": [
        "dummy=dummy.drop(['mths_since_last_delinq','mths_since_last_record','mths_since_last_major_derog'],axis=1) "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gLX72V87dKL"
      },
      "source": [
        "checking corelation between independent numeeric variables\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur40mPxX7dKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f043842c-59c1-4bc1-b138-93db8851b20f"
      },
      "source": [
        "print(dummy.corr(method ='pearson'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            loan_amnt  funded_amnt  funded_amnt_inv  int_rate  \\\n",
            "loan_amnt                    1.000000     0.999265         0.997601  0.142966   \n",
            "funded_amnt                  0.999265     1.000000         0.998485  0.143116   \n",
            "funded_amnt_inv              0.997601     0.998485         1.000000  0.143374   \n",
            "int_rate                     0.142966     0.143116         0.143374  1.000000   \n",
            "installment                  0.944870     0.945903         0.944149  0.130468   \n",
            "annual_inc                   0.335209     0.335002         0.334356 -0.073825   \n",
            "dti                          0.020189     0.020583         0.021489  0.078454   \n",
            "delinq_2yrs                 -0.000739    -0.000424         0.000050  0.055400   \n",
            "inq_last_6mths              -0.028928    -0.029279        -0.030462  0.231705   \n",
            "open_acc                     0.198926     0.199432         0.200055 -0.011091   \n",
            "pub_rec                     -0.082199    -0.081858        -0.081008  0.052596   \n",
            "revol_bal                    0.337489     0.337405         0.336870 -0.035344   \n",
            "revol_util                   0.119635     0.120147         0.120931  0.271687   \n",
            "total_acc                    0.222084     0.222039         0.222258 -0.039482   \n",
            "out_prncp                    0.639784     0.641706         0.644011  0.033933   \n",
            "out_prncp_inv                0.639786     0.641709         0.644023  0.033790   \n",
            "total_pymnt                  0.479612     0.478290         0.474600  0.173387   \n",
            "total_pymnt_inv              0.480328     0.479172         0.478589  0.174453   \n",
            "total_rec_prncp              0.395880     0.394669         0.391010  0.059298   \n",
            "total_rec_int                0.537586     0.536533         0.534517  0.446517   \n",
            "total_rec_late_fee           0.025966     0.025579         0.023091  0.050743   \n",
            "recoveries                   0.075513     0.075076         0.073737  0.110848   \n",
            "collection_recovery_fee      0.055135     0.054898         0.053082  0.074360   \n",
            "last_pymnt_amnt              0.233596     0.233134         0.232029  0.107346   \n",
            "collections_12_mths_ex_med  -0.017042    -0.016887        -0.016556  0.012841   \n",
            "acc_now_delinq               0.003572     0.003675         0.003856  0.026476   \n",
            "tot_coll_amt                -0.004272    -0.004272        -0.004271  0.001129   \n",
            "tot_cur_bal                  0.329130     0.329128         0.329152 -0.091430   \n",
            "total_rev_hi_lim             0.312072     0.312071         0.312107 -0.165533   \n",
            "default_ind                 -0.004907    -0.005797        -0.008209  0.155037   \n",
            "\n",
            "                            installment  annual_inc       dti  delinq_2yrs  \\\n",
            "loan_amnt                      0.944870    0.335209  0.020189    -0.000739   \n",
            "funded_amnt                    0.945903    0.335002  0.020583    -0.000424   \n",
            "funded_amnt_inv                0.944149    0.334356  0.021489     0.000050   \n",
            "int_rate                       0.130468   -0.073825  0.078454     0.055400   \n",
            "installment                    1.000000    0.328578  0.013909     0.007224   \n",
            "annual_inc                     0.328578    1.000000 -0.086821     0.047749   \n",
            "dti                            0.013909   -0.086821  1.000000    -0.002677   \n",
            "delinq_2yrs                    0.007224    0.047749 -0.002677     1.000000   \n",
            "inq_last_6mths                 0.001659    0.037251 -0.005860     0.022930   \n",
            "open_acc                       0.183817    0.139429  0.142068     0.051502   \n",
            "pub_rec                       -0.071114   -0.008909 -0.022717    -0.011081   \n",
            "revol_bal                      0.320017    0.298569  0.067119    -0.031807   \n",
            "revol_util                     0.131928    0.036753  0.086649    -0.016299   \n",
            "total_acc                      0.199872    0.188651  0.106266     0.121978   \n",
            "out_prncp                      0.539840    0.211549  0.058057     0.030884   \n",
            "out_prncp_inv                  0.539835    0.211591  0.058021     0.030874   \n",
            "total_pymnt                    0.520613    0.163226 -0.040537    -0.031777   \n",
            "total_pymnt_inv                0.521332    0.163275 -0.039563    -0.031346   \n",
            "total_rec_prncp                0.455444    0.152245 -0.050855    -0.038068   \n",
            "total_rec_int                  0.502038    0.130367  0.008750     0.001380   \n",
            "total_rec_late_fee             0.035728    0.009864 -0.006245     0.013992   \n",
            "recoveries                     0.076931    0.007613  0.001719    -0.000252   \n",
            "collection_recovery_fee        0.057180    0.006805  0.002923     0.001467   \n",
            "last_pymnt_amnt                0.243246    0.092662 -0.028601    -0.018805   \n",
            "collections_12_mths_ex_med    -0.014565   -0.003789 -0.000117     0.063019   \n",
            "acc_now_delinq                 0.006273    0.014877  0.003227     0.130420   \n",
            "tot_coll_amt                  -0.003540    0.001005 -0.001995     0.000154   \n",
            "tot_cur_bal                    0.298352    0.422618 -0.007133     0.064618   \n",
            "total_rev_hi_lim               0.286857    0.271059  0.032430    -0.040575   \n",
            "default_ind                    0.004753   -0.037066  0.004429    -0.009186   \n",
            "\n",
            "                            inq_last_6mths  open_acc   pub_rec  revol_bal  \\\n",
            "loan_amnt                        -0.028928  0.198926 -0.082199   0.337489   \n",
            "funded_amnt                      -0.029279  0.199432 -0.081858   0.337405   \n",
            "funded_amnt_inv                  -0.030462  0.200055 -0.081008   0.336870   \n",
            "int_rate                          0.231705 -0.011091  0.052596  -0.035344   \n",
            "installment                       0.001659  0.183817 -0.071114   0.320017   \n",
            "annual_inc                        0.037251  0.139429 -0.008909   0.298569   \n",
            "dti                              -0.005860  0.142068 -0.022717   0.067119   \n",
            "delinq_2yrs                       0.022930  0.051502 -0.011081  -0.031807   \n",
            "inq_last_6mths                    1.000000  0.116532  0.059430  -0.018683   \n",
            "open_acc                          0.116532  1.000000 -0.026122   0.225858   \n",
            "pub_rec                           0.059430 -0.026122  1.000000  -0.101235   \n",
            "revol_bal                        -0.018683  0.225858 -0.101235   1.000000   \n",
            "revol_util                       -0.088353 -0.144959 -0.079050   0.217785   \n",
            "total_acc                         0.141854  0.694850  0.012300   0.189322   \n",
            "out_prncp                        -0.104062  0.171050 -0.007978   0.236093   \n",
            "out_prncp_inv                    -0.104083  0.171053 -0.007976   0.236100   \n",
            "total_pymnt                       0.080476  0.043452 -0.087933   0.139161   \n",
            "total_pymnt_inv                   0.079531  0.044552 -0.087299   0.139355   \n",
            "total_rec_prncp                   0.065010  0.032115 -0.084596   0.120577   \n",
            "total_rec_int                     0.088495  0.061725 -0.059868   0.139872   \n",
            "total_rec_late_fee                0.022820 -0.009957 -0.011871  -0.000166   \n",
            "recoveries                        0.044004  0.001957 -0.014602   0.010861   \n",
            "collection_recovery_fee           0.029647  0.003990 -0.008963   0.008588   \n",
            "last_pymnt_amnt                   0.065455  0.029130 -0.034215   0.060027   \n",
            "collections_12_mths_ex_med        0.007364  0.009998  0.020874  -0.022552   \n",
            "acc_now_delinq                   -0.004836  0.017774 -0.000293  -0.000677   \n",
            "tot_coll_amt                      0.003181  0.000071  0.006816  -0.006117   \n",
            "tot_cur_bal                       0.034806  0.244465 -0.075956   0.443059   \n",
            "total_rev_hi_lim                  0.006089  0.325179 -0.100227   0.820800   \n",
            "default_ind                       0.074407 -0.021698 -0.019607  -0.020696   \n",
            "\n",
            "                            revol_util  total_acc  out_prncp  out_prncp_inv  \\\n",
            "loan_amnt                     0.119635   0.222084   0.639784       0.639786   \n",
            "funded_amnt                   0.120147   0.222039   0.641706       0.641709   \n",
            "funded_amnt_inv               0.120931   0.222258   0.644011       0.644023   \n",
            "int_rate                      0.271687  -0.039482   0.033933       0.033790   \n",
            "installment                   0.131928   0.199872   0.539840       0.539835   \n",
            "annual_inc                    0.036753   0.188651   0.211549       0.211591   \n",
            "dti                           0.086649   0.106266   0.058057       0.058021   \n",
            "delinq_2yrs                  -0.016299   0.121978   0.030884       0.030874   \n",
            "inq_last_6mths               -0.088353   0.141854  -0.104062      -0.104083   \n",
            "open_acc                     -0.144959   0.694850   0.171050       0.171053   \n",
            "pub_rec                      -0.079050   0.012300  -0.007978      -0.007976   \n",
            "revol_bal                     0.217785   0.189322   0.236093       0.236100   \n",
            "revol_util                    1.000000  -0.114616   0.074353       0.074302   \n",
            "total_acc                    -0.114616   1.000000   0.135755       0.135770   \n",
            "out_prncp                     0.074353   0.135755   1.000000       0.999997   \n",
            "out_prncp_inv                 0.074302   0.135770   0.999997       1.000000   \n",
            "total_pymnt                   0.080945   0.110169  -0.289173      -0.289164   \n",
            "total_pymnt_inv               0.082181   0.110983  -0.286487      -0.286472   \n",
            "total_rec_prncp               0.036756   0.101289  -0.370627      -0.370620   \n",
            "total_rec_int                 0.183754   0.091824   0.112191       0.112205   \n",
            "total_rec_late_fee            0.019445  -0.005655  -0.046704      -0.046707   \n",
            "recoveries                    0.029601   0.009670  -0.111595      -0.111595   \n",
            "collection_recovery_fee       0.019880   0.011048  -0.077588      -0.077588   \n",
            "last_pymnt_amnt              -0.000939   0.087729  -0.333641      -0.333641   \n",
            "collections_12_mths_ex_med   -0.035707   0.009181   0.015653       0.015638   \n",
            "acc_now_delinq               -0.027270   0.026633   0.011834       0.011824   \n",
            "tot_coll_amt                 -0.009252   0.006463  -0.000840      -0.000841   \n",
            "tot_cur_bal                   0.080583   0.311268   0.207565       0.207597   \n",
            "total_rev_hi_lim             -0.117724   0.255391   0.221319       0.221361   \n",
            "default_ind                   0.044497  -0.021087  -0.225960      -0.225959   \n",
            "\n",
            "                            total_pymnt  total_pymnt_inv  total_rec_prncp  \\\n",
            "loan_amnt                      0.479612         0.480328         0.395880   \n",
            "funded_amnt                    0.478290         0.479172         0.394669   \n",
            "funded_amnt_inv                0.474600         0.478589         0.391010   \n",
            "int_rate                       0.173387         0.174453         0.059298   \n",
            "installment                    0.520613         0.521332         0.455444   \n",
            "annual_inc                     0.163226         0.163275         0.152245   \n",
            "dti                           -0.040537        -0.039563        -0.050855   \n",
            "delinq_2yrs                   -0.031777        -0.031346        -0.038068   \n",
            "inq_last_6mths                 0.080476         0.079531         0.065010   \n",
            "open_acc                       0.043452         0.044552         0.032115   \n",
            "pub_rec                       -0.087933        -0.087299        -0.084596   \n",
            "revol_bal                      0.139161         0.139355         0.120577   \n",
            "revol_util                     0.080945         0.082181         0.036756   \n",
            "total_acc                      0.110169         0.110983         0.101289   \n",
            "out_prncp                     -0.289173        -0.286487        -0.370627   \n",
            "out_prncp_inv                 -0.289164        -0.286472        -0.370620   \n",
            "total_pymnt                    1.000000         0.998121         0.970594   \n",
            "total_pymnt_inv                0.998121         1.000000         0.968608   \n",
            "total_rec_prncp                0.970594         0.968608         1.000000   \n",
            "total_rec_int                  0.679127         0.678519         0.488377   \n",
            "total_rec_late_fee             0.054403         0.052077         0.033519   \n",
            "recoveries                     0.037201         0.036396        -0.039655   \n",
            "collection_recovery_fee        0.035844         0.034366        -0.024295   \n",
            "last_pymnt_amnt                0.662738         0.663272         0.744494   \n",
            "collections_12_mths_ex_med    -0.038618        -0.038350        -0.037766   \n",
            "acc_now_delinq                -0.008220        -0.008021        -0.010486   \n",
            "tot_coll_amt                  -0.004203        -0.004202        -0.003788   \n",
            "tot_cur_bal                    0.169289         0.169301         0.157435   \n",
            "total_rev_hi_lim               0.120593         0.120602         0.118982   \n",
            "default_ind                   -0.039220        -0.040232        -0.090336   \n",
            "\n",
            "                            total_rec_int  total_rec_late_fee  recoveries  \\\n",
            "loan_amnt                        0.537586            0.025966    0.075513   \n",
            "funded_amnt                      0.536533            0.025579    0.075076   \n",
            "funded_amnt_inv                  0.534517            0.023091    0.073737   \n",
            "int_rate                         0.446517            0.050743    0.110848   \n",
            "installment                      0.502038            0.035728    0.076931   \n",
            "annual_inc                       0.130367            0.009864    0.007613   \n",
            "dti                              0.008750           -0.006245    0.001719   \n",
            "delinq_2yrs                      0.001380            0.013992   -0.000252   \n",
            "inq_last_6mths                   0.088495            0.022820    0.044004   \n",
            "open_acc                         0.061725           -0.009957    0.001957   \n",
            "pub_rec                         -0.059868           -0.011871   -0.014602   \n",
            "revol_bal                        0.139872           -0.000166    0.010861   \n",
            "revol_util                       0.183754            0.019445    0.029601   \n",
            "total_acc                        0.091824           -0.005655    0.009670   \n",
            "out_prncp                        0.112191           -0.046704   -0.111595   \n",
            "out_prncp_inv                    0.112205           -0.046707   -0.111595   \n",
            "total_pymnt                      0.679127            0.054403    0.037201   \n",
            "total_pymnt_inv                  0.678519            0.052077    0.036396   \n",
            "total_rec_prncp                  0.488377            0.033519   -0.039655   \n",
            "total_rec_int                    1.000000            0.080459    0.069917   \n",
            "total_rec_late_fee               0.080459            1.000000    0.085700   \n",
            "recoveries                       0.069917            0.085700    1.000000   \n",
            "collection_recovery_fee          0.054602            0.078744    0.803029   \n",
            "last_pymnt_amnt                  0.137991           -0.009496   -0.038542   \n",
            "collections_12_mths_ex_med      -0.024670           -0.003835   -0.004684   \n",
            "acc_now_delinq                   0.002220            0.002229    0.000883   \n",
            "tot_coll_amt                    -0.003562           -0.000592   -0.000919   \n",
            "tot_cur_bal                      0.134022            0.008831    0.004063   \n",
            "total_rev_hi_lim                 0.073855           -0.005545   -0.000171   \n",
            "default_ind                      0.046050            0.140760    0.475738   \n",
            "\n",
            "                            collection_recovery_fee  last_pymnt_amnt  \\\n",
            "loan_amnt                                  0.055135         0.233596   \n",
            "funded_amnt                                0.054898         0.233134   \n",
            "funded_amnt_inv                            0.053082         0.232029   \n",
            "int_rate                                   0.074360         0.107346   \n",
            "installment                                0.057180         0.243246   \n",
            "annual_inc                                 0.006805         0.092662   \n",
            "dti                                        0.002923        -0.028601   \n",
            "delinq_2yrs                                0.001467        -0.018805   \n",
            "inq_last_6mths                             0.029647         0.065455   \n",
            "open_acc                                   0.003990         0.029130   \n",
            "pub_rec                                   -0.008963        -0.034215   \n",
            "revol_bal                                  0.008588         0.060027   \n",
            "revol_util                                 0.019880        -0.000939   \n",
            "total_acc                                  0.011048         0.087729   \n",
            "out_prncp                                 -0.077588        -0.333641   \n",
            "out_prncp_inv                             -0.077588        -0.333641   \n",
            "total_pymnt                                0.035844         0.662738   \n",
            "total_pymnt_inv                            0.034366         0.663272   \n",
            "total_rec_prncp                           -0.024295         0.744494   \n",
            "total_rec_int                              0.054602         0.137991   \n",
            "total_rec_late_fee                         0.078744        -0.009496   \n",
            "recoveries                                 0.803029        -0.038542   \n",
            "collection_recovery_fee                    1.000000        -0.026610   \n",
            "last_pymnt_amnt                           -0.026610         1.000000   \n",
            "collections_12_mths_ex_med                -0.002866        -0.017771   \n",
            "acc_now_delinq                             0.000557        -0.002911   \n",
            "tot_coll_amt                              -0.000514        -0.002568   \n",
            "tot_cur_bal                                0.005704         0.103113   \n",
            "total_rev_hi_lim                           0.001399         0.062068   \n",
            "default_ind                                0.330764        -0.087217   \n",
            "\n",
            "                            collections_12_mths_ex_med  acc_now_delinq  \\\n",
            "loan_amnt                                    -0.017042        0.003572   \n",
            "funded_amnt                                  -0.016887        0.003675   \n",
            "funded_amnt_inv                              -0.016556        0.003856   \n",
            "int_rate                                      0.012841        0.026476   \n",
            "installment                                  -0.014565        0.006273   \n",
            "annual_inc                                   -0.003789        0.014877   \n",
            "dti                                          -0.000117        0.003227   \n",
            "delinq_2yrs                                   0.063019        0.130420   \n",
            "inq_last_6mths                                0.007364       -0.004836   \n",
            "open_acc                                      0.009998        0.017774   \n",
            "pub_rec                                       0.020874       -0.000293   \n",
            "revol_bal                                    -0.022552       -0.000677   \n",
            "revol_util                                   -0.035707       -0.027270   \n",
            "total_acc                                     0.009181        0.026633   \n",
            "out_prncp                                     0.015653        0.011834   \n",
            "out_prncp_inv                                 0.015638        0.011824   \n",
            "total_pymnt                                  -0.038618       -0.008220   \n",
            "total_pymnt_inv                              -0.038350       -0.008021   \n",
            "total_rec_prncp                              -0.037766       -0.010486   \n",
            "total_rec_int                                -0.024670        0.002220   \n",
            "total_rec_late_fee                           -0.003835        0.002229   \n",
            "recoveries                                   -0.004684        0.000883   \n",
            "collection_recovery_fee                      -0.002866        0.000557   \n",
            "last_pymnt_amnt                              -0.017771       -0.002911   \n",
            "collections_12_mths_ex_med                    1.000000        0.040197   \n",
            "acc_now_delinq                                0.040197        1.000000   \n",
            "tot_coll_amt                                  0.009686        0.000267   \n",
            "tot_cur_bal                                  -0.010622        0.022804   \n",
            "total_rev_hi_lim                             -0.016808        0.008254   \n",
            "default_ind                                  -0.010650       -0.003116   \n",
            "\n",
            "                            tot_coll_amt  tot_cur_bal  total_rev_hi_lim  \\\n",
            "loan_amnt                      -0.004272     0.329130          0.312072   \n",
            "funded_amnt                    -0.004272     0.329128          0.312071   \n",
            "funded_amnt_inv                -0.004271     0.329152          0.312107   \n",
            "int_rate                        0.001129    -0.091430         -0.165533   \n",
            "installment                    -0.003540     0.298352          0.286857   \n",
            "annual_inc                      0.001005     0.422618          0.271059   \n",
            "dti                            -0.001995    -0.007133          0.032430   \n",
            "delinq_2yrs                     0.000154     0.064618         -0.040575   \n",
            "inq_last_6mths                  0.003181     0.034806          0.006089   \n",
            "open_acc                        0.000071     0.244465          0.325179   \n",
            "pub_rec                         0.006816    -0.075956         -0.100227   \n",
            "revol_bal                      -0.006117     0.443059          0.820800   \n",
            "revol_util                     -0.009252     0.080583         -0.117724   \n",
            "total_acc                       0.006463     0.311268          0.255391   \n",
            "out_prncp                      -0.000840     0.207565          0.221319   \n",
            "out_prncp_inv                  -0.000841     0.207597          0.221361   \n",
            "total_pymnt                    -0.004203     0.169289          0.120593   \n",
            "total_pymnt_inv                -0.004202     0.169301          0.120602   \n",
            "total_rec_prncp                -0.003788     0.157435          0.118982   \n",
            "total_rec_int                  -0.003562     0.134022          0.073855   \n",
            "total_rec_late_fee             -0.000592     0.008831         -0.005545   \n",
            "recoveries                     -0.000919     0.004063         -0.000171   \n",
            "collection_recovery_fee        -0.000514     0.005704          0.001399   \n",
            "last_pymnt_amnt                -0.002568     0.103113          0.062068   \n",
            "collections_12_mths_ex_med      0.009686    -0.010622         -0.016808   \n",
            "acc_now_delinq                  0.000267     0.022804          0.008254   \n",
            "tot_coll_amt                    1.000000    -0.000331         -0.005025   \n",
            "tot_cur_bal                    -0.000331     1.000000          0.384867   \n",
            "total_rev_hi_lim               -0.005025     0.384867          1.000000   \n",
            "default_ind                    -0.001921    -0.036335         -0.033620   \n",
            "\n",
            "                            default_ind  \n",
            "loan_amnt                     -0.004907  \n",
            "funded_amnt                   -0.005797  \n",
            "funded_amnt_inv               -0.008209  \n",
            "int_rate                       0.155037  \n",
            "installment                    0.004753  \n",
            "annual_inc                    -0.037066  \n",
            "dti                            0.004429  \n",
            "delinq_2yrs                   -0.009186  \n",
            "inq_last_6mths                 0.074407  \n",
            "open_acc                      -0.021698  \n",
            "pub_rec                       -0.019607  \n",
            "revol_bal                     -0.020696  \n",
            "revol_util                     0.044497  \n",
            "total_acc                     -0.021087  \n",
            "out_prncp                     -0.225960  \n",
            "out_prncp_inv                 -0.225959  \n",
            "total_pymnt                   -0.039220  \n",
            "total_pymnt_inv               -0.040232  \n",
            "total_rec_prncp               -0.090336  \n",
            "total_rec_int                  0.046050  \n",
            "total_rec_late_fee             0.140760  \n",
            "recoveries                     0.475738  \n",
            "collection_recovery_fee        0.330764  \n",
            "last_pymnt_amnt               -0.087217  \n",
            "collections_12_mths_ex_med    -0.010650  \n",
            "acc_now_delinq                -0.003116  \n",
            "tot_coll_amt                  -0.001921  \n",
            "tot_cur_bal                   -0.036335  \n",
            "total_rev_hi_lim              -0.033620  \n",
            "default_ind                    1.000000  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjWW9zQ47dKS"
      },
      "source": [
        "Loan_amnt, funded_amnt and funded_amnt_inv are highly corelated so keeping just one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIX_2YAk7dKT"
      },
      "source": [
        "dummy=dummy.drop(['funded_amnt','funded_amnt_inv'],axis=1) "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLyjtHPv7dKW"
      },
      "source": [
        "out_prncp_inv  and out_prncp are highly corelated so keeping just one<br>\n",
        "total_pymnt  total_pymnt_inv and total_rec_prncp are highly corelated so keeping just one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwyxlyIV7dKX"
      },
      "source": [
        "dummy=dummy.drop(['out_prncp_inv','total_pymnt_inv','total_rec_prncp'],axis=1) "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYx0G7RU7dKc"
      },
      "source": [
        "Handling date variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5Rst2pA7dKd"
      },
      "source": [
        "Removing insignificant Date variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3L6Z7P47dKd"
      },
      "source": [
        "dummy=dummy.drop(['next_pymnt_d'],axis=1) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji04hhvv7dKj"
      },
      "source": [
        "Changing the format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXIu3pHd7dKk"
      },
      "source": [
        "dummy['issue_d'] = pd.to_datetime(dummy['issue_d'],infer_datetime_format=True, yearfirst=False)\n",
        "#dummy['earliest_cr_line'] = pd.to_datetime(dummy['earliest_cr_line'],infer_datetime_format=True, yearfirst=False)\n",
        "#dummy['last_credit_pull_d'] = pd.to_datetime(dummy['last_credit_pull_d'],infer_datetime_format=True, yearfirst=False)\n",
        "#dummy['last_pymnt_d'] = pd.to_datetime(dummy['last_pymnt_d'],infer_datetime_format=True, yearfirst=False)\n",
        "#%%\n",
        "#converting to year\n",
        "#dummy['earliest_cr_line'] = dummy['earliest_cr_line'].apply(lambda x: x.year)\n",
        "#dummy['last_credit_pull_d'] = dummy['last_credit_pull_d'].apply(lambda x: x.year)\n",
        "#dummy['last_pymnt_d'] = dummy['last_pymnt_d'].apply(lambda x: x.year)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9Ifw6Aq7dKp"
      },
      "source": [
        "Data edits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPSnCnov7dKr"
      },
      "source": [
        "#removing spaces\n",
        "dummy.emp_length=dummy.emp_length.replace('10+ years','ten') \n",
        "dummy.emp_length=dummy.emp_length.replace('2 years','two') \n",
        "dummy.emp_length=dummy.emp_length.replace('< 1 year','zero') \n",
        "dummy.emp_length=dummy.emp_length.replace('3 years','three') \n",
        "dummy.emp_length=dummy.emp_length.replace('1 year','one') \n",
        "dummy.emp_length=dummy.emp_length.replace('5 years','five') \n",
        "dummy.emp_length=dummy.emp_length.replace('4 years','four') \n",
        "dummy.emp_length=dummy.emp_length.replace('7 years','seven') \n",
        "dummy.emp_length=dummy.emp_length.replace('8 years','eight') \n",
        "dummy.emp_length=dummy.emp_length.replace('6 years','six') \n",
        "dummy.emp_length=dummy.emp_length.replace('9 years','nine') "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v5DOmE47dKw"
      },
      "source": [
        "Data edits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gv69N7t7dKx"
      },
      "source": [
        "#dummy.home_ownership=dummy.home_ownership.replace('NONE','OTHER') \n",
        "#dummy.home_ownership=dummy.home_ownership.replace('ANY','OTHER') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7U5JiUk7dK3"
      },
      "source": [
        "Data edits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad7hnqfT7dK4"
      },
      "source": [
        "#Source Verified and Verified both have same meaning\r\n",
        "dummy.verification_status=dummy.verification_status.replace('Source Verified','Verified') "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KpUMNtsA6Hu"
      },
      "source": [
        "Treating missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kay_07fA2eC",
        "outputId": "15bc22a3-4c8f-49b2-ddc6-228719db21f3"
      },
      "source": [
        "dummy.isnull().sum()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "loan_amnt                         0\n",
              "term                              0\n",
              "int_rate                          0\n",
              "installment                       0\n",
              "sub_grade                         0\n",
              "emp_length                    43061\n",
              "home_ownership                    0\n",
              "annual_inc                        0\n",
              "verification_status               0\n",
              "issue_d                           0\n",
              "purpose                           0\n",
              "dti                               0\n",
              "delinq_2yrs                       0\n",
              "earliest_cr_line                  0\n",
              "inq_last_6mths                    0\n",
              "open_acc                          0\n",
              "pub_rec                           0\n",
              "revol_bal                         0\n",
              "revol_util                      446\n",
              "total_acc                         0\n",
              "initial_list_status               0\n",
              "out_prncp                         0\n",
              "total_pymnt                       0\n",
              "total_rec_int                     0\n",
              "total_rec_late_fee                0\n",
              "recoveries                        0\n",
              "collection_recovery_fee           0\n",
              "last_pymnt_d                   8862\n",
              "last_pymnt_amnt                   0\n",
              "last_credit_pull_d               50\n",
              "collections_12_mths_ex_med       56\n",
              "application_type                  0\n",
              "acc_now_delinq                    0\n",
              "tot_coll_amt                  67313\n",
              "tot_cur_bal                   67313\n",
              "total_rev_hi_lim              67313\n",
              "default_ind                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P7VWy0y7dLB"
      },
      "source": [
        "dummy['emp_length'].fillna(dummy['emp_length'].mode()[0],inplace=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdi1eH8xFT_f"
      },
      "source": [
        "dummy['revol_util'].fillna(round(dummy['revol_util'].mean(),0),inplace=True) #rounding of to 0"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-tqxQO2F7u-"
      },
      "source": [
        "dummy['tot_cur_bal'].fillna(round(dummy['tot_cur_bal'].mode()[0]),inplace=True) \r\n",
        "dummy['last_pymnt_d'].fillna((dummy['last_pymnt_d'].mode()[0]),inplace=True) \r\n",
        "dummy['last_credit_pull_d'].fillna((dummy['last_credit_pull_d'].mode()[0]),inplace=True) \r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coP0aWpqF70G"
      },
      "source": [
        "dummy['total_rev_hi_lim'].fillna(round(dummy['total_rev_hi_lim'].mode()[0]),inplace=True) #rounding of to 0\r\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkktIfKxFUF-"
      },
      "source": [
        "dummy['collections_12_mths_ex_med'].fillna(round(dummy['collections_12_mths_ex_med'].mean(),0),inplace=True) #rounding of to 0\r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F9YTzV0FUM7"
      },
      "source": [
        "dummy['tot_coll_amt'].fillna(round(dummy['tot_coll_amt'].mode()[0]),inplace=True) #rounding of to 0"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU9MmtGO7dLL"
      },
      "source": [
        "Treating outliers \r\n",
        "\r\n",
        "Didn't found any significant differences in performance by treating outliers hence commented below codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nTmSCn_7dLM"
      },
      "source": [
        "#q1 = dummy['int_rate'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['int_rate'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFSolGDe7dLU"
      },
      "source": [
        "#dummy.loc[dummy[\"int_rate\"] >high, \"int_rate\"] = high\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoJtR-847dLZ"
      },
      "source": [
        "#q1 = dummy['installment'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['installment'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbSb-t9v7dLb"
      },
      "source": [
        "#dummy.loc[dummy[\"installment\"] >high, \"installment\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYqnwboF7dLg"
      },
      "source": [
        "#q1 = dummy['annual_inc'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['annual_inc'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEjOjkB57dLj"
      },
      "source": [
        "#dummy.loc[dummy[\"annual_inc\"] >high, \"annual_inc\"] = high\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTR1Y0CV7dLp"
      },
      "source": [
        "#q1 = dummy['dti'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['dti'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range\n",
        "#dummy.loc[dummy[\"dti\"] >high, \"dti\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNMfLfsr7dLx"
      },
      "source": [
        "#q1 = dummy['open_acc'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['open_acc'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range\n",
        "#dummy.loc[dummy[\"open_acc\"] >high, \"open_acc\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PYTs4zs7dL5"
      },
      "source": [
        "#q1 = dummy['revol_bal'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['revol_bal'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range\n",
        "#dummy.loc[dummy[\"revol_bal\"] >high, \"revol_bal\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llEjWhBO7dMB"
      },
      "source": [
        "#q1 = dummy['total_acc'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['total_acc'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range\n",
        "#dummy.loc[dummy[\"total_acc\"] >high, \"total_acc\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE4P3tkj7dMJ"
      },
      "source": [
        "#q1 = dummy['out_prncp'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['out_prncp'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range\n",
        "#dummy.loc[dummy[\"out_prncp\"] >high, \"out_prncp\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Glxelns7dMT"
      },
      "source": [
        "#q1 = dummy['total_pymnt'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['total_pymnt'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range\n",
        "#dummy.loc[dummy[\"total_pymnt\"] >high, \"total_pymnt\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kyq-HEU7dMe"
      },
      "source": [
        "#q1 = dummy['total_rec_int'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['total_rec_int'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range\n",
        "#dummy.loc[dummy[\"total_rec_int\"] >high, \"total_rec_int\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD3qXWOK7dMn"
      },
      "source": [
        "#q1 = dummy['last_pymnt_amnt'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['last_pymnt_amnt'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range\n",
        "#dummy.loc[dummy[\"last_pymnt_amnt\"] >high, \"last_pymnt_amnt\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnKA-QuV7dMx"
      },
      "source": [
        "#q1 = dummy['revol_util'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['revol_util'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range\n",
        "#dummy.loc[dummy[\"revol_util\"] >high, \"revol_util\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfZ1Bsmp7dNE"
      },
      "source": [
        "#q1 = dummy['tot_cur_bal'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['tot_cur_bal'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range\n",
        "#dummy.loc[dummy[\"tot_cur_bal\"] >high, \"tot_cur_bal\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhDRx3LP7dNQ"
      },
      "source": [
        "#q1 = dummy['total_rev_hi_lim'].quantile(0.25) #first quartile value\n",
        "#q3 = dummy['total_rev_hi_lim'].quantile(0.75) # third quartile value\n",
        "#iqr = q3-q1 #Interquartile range\n",
        "#low  = q1-1.5*iqr #acceptable range\n",
        "#high = q3+1.5*iqr #acceptable range\n",
        "#dummy.loc[dummy[\"total_rev_hi_lim\"] >high, \"total_rev_hi_lim\"] = high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zy23DP87dNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62193e4c-e76c-4a97-fa88-bc894f13a9b7"
      },
      "source": [
        "dummy.isnull().sum()  #checking missing values\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "loan_amnt                     0\n",
              "term                          0\n",
              "int_rate                      0\n",
              "installment                   0\n",
              "sub_grade                     0\n",
              "emp_length                    0\n",
              "home_ownership                0\n",
              "annual_inc                    0\n",
              "verification_status           0\n",
              "issue_d                       0\n",
              "purpose                       0\n",
              "dti                           0\n",
              "delinq_2yrs                   0\n",
              "earliest_cr_line              0\n",
              "inq_last_6mths                0\n",
              "open_acc                      0\n",
              "pub_rec                       0\n",
              "revol_bal                     0\n",
              "revol_util                    0\n",
              "total_acc                     0\n",
              "initial_list_status           0\n",
              "out_prncp                     0\n",
              "total_pymnt                   0\n",
              "total_rec_int                 0\n",
              "total_rec_late_fee            0\n",
              "recoveries                    0\n",
              "collection_recovery_fee       0\n",
              "last_pymnt_d                  0\n",
              "last_pymnt_amnt               0\n",
              "last_credit_pull_d            0\n",
              "collections_12_mths_ex_med    0\n",
              "application_type              0\n",
              "acc_now_delinq                0\n",
              "tot_coll_amt                  0\n",
              "tot_cur_bal                   0\n",
              "total_rev_hi_lim              0\n",
              "default_ind                   0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-iIIsPO-RBL"
      },
      "source": [
        "categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y738kKm-7dNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5165211b-1d07-418f-d799-ddc5ead7b671"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "colname=[]\n",
        "for x in dummy.columns[:] :\n",
        "    if dummy[x].dtype=='object':   #find all categorical value\n",
        "        colname.append(x)   #add all categorical to list\n",
        "#    else:\n",
        "#      if x not in ['issue_d','default_ind']:\n",
        "#        dummy[x]=scaler.fit_transform(np.array(dummy[x]).reshape(-1,1))\n",
        "colname"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['term',\n",
              " 'sub_grade',\n",
              " 'emp_length',\n",
              " 'home_ownership',\n",
              " 'verification_status',\n",
              " 'purpose',\n",
              " 'earliest_cr_line',\n",
              " 'initial_list_status',\n",
              " 'last_pymnt_d',\n",
              " 'last_credit_pull_d',\n",
              " 'application_type']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIdSHQLKWMpb"
      },
      "source": [
        "term        = pd.get_dummies(dummy.term       ,prefix='term'\t, drop_first = True)\n",
        "sub_grade    = pd.get_dummies(dummy.sub_grade   ,prefix='sub_grade'  , drop_first = True)\n",
        "emp_length      = pd.get_dummies(dummy.emp_length     ,prefix='emp_length'    , drop_first = True)\n",
        "home_ownership      = pd.get_dummies(dummy.home_ownership     ,prefix='home_ownership'    , drop_first = True)\n",
        "verification_status        = pd.get_dummies(dummy.verification_status       ,prefix='verification_status'\t, drop_first = True)\n",
        "purpose      = pd.get_dummies(dummy.purpose     ,prefix='purpose'\t, drop_first = True)\n",
        "#earliest_cr_line       = pd.get_dummies(dummy.earliest_cr_line      ,prefix='earliest_cr_line'\t, drop_first = True)\n",
        "initial_list_status        = pd.get_dummies(dummy.initial_list_status       ,prefix='initial_list_status'\t, drop_first = True)\n",
        "#last_pymnt_d       = pd.get_dummies(dummy.last_pymnt_d      ,prefix='last_pymnt_d'\t, drop_first = True)\n",
        "#last_credit_pull_d        = pd.get_dummies(dummy.last_credit_pull_d       ,prefix='last_credit_pull_d'\t, drop_first = True)\n",
        "application_type    = pd.get_dummies(dummy.application_type   ,prefix='application_type'\t, drop_first = True)\n",
        "\n",
        "dummy= pd.concat([dummy,term,sub_grade,emp_length,home_ownership,verification_status,purpose\n",
        "                    ,initial_list_status,application_type], axis = 1)\n",
        "\n",
        "#removing categorical column\n",
        "dummy = dummy.drop(['term', 'sub_grade', 'emp_length', 'home_ownership', 'verification_status', 'purpose', 'earliest_cr_line',\n",
        " 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type'], axis = 1)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlJsp9MJXXIW",
        "outputId": "b0674ee5-8d33-4737-8a2f-e4a6cafa8295"
      },
      "source": [
        "#randomizing the data\n",
        "dummy = dummy.sample(frac = 1) \n",
        "dummy.shape\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(855969, 92)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4qmg0UG7dOf"
      },
      "source": [
        "#df_DT=pd.DataFrame.copy(dummy) \n",
        "df=pd.DataFrame.copy(dummy) "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPeVZIRu7dOh"
      },
      "source": [
        "Splitting data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzv8nnhl7dOi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test_size = 0.1\n",
        "seed = 11\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df.drop('default_ind',axis=1), df['default_ind'],\n",
        "test_size = test_size, random_state = seed, stratify = df['default_ind'])\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjvH01dDdY6j",
        "outputId": "b6c87a4d-7960-4fcc-9b2f-fdf6c197e802"
      },
      "source": [
        "print(Y_train.value_counts())\n",
        "print(Y_test.value_counts())\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    728552\n",
            "1     41820\n",
            "Name: default_ind, dtype: int64\n",
            "0    80950\n",
            "1     4647\n",
            "Name: default_ind, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRNZDXZ37dOk"
      },
      "source": [
        "Standardizing numeric data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF2vw4YC7dOk"
      },
      "source": [
        "numlist=['loan_amnt', 'int_rate', 'installment', 'annual_inc', 'issue_d', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'out_prncp',\n",
        "'total_pymnt', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_amnt', 'collections_12_mths_ex_med', 'acc_now_delinq', 'tot_coll_amt',\n",
        "'tot_cur_bal', 'total_rev_hi_lim']\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "for x in numlist :\n",
        "  scaler = MinMaxScaler()\n",
        "  scaler1=scaler.fit(np.array(X_train[x]).reshape(-1,1))\n",
        "  X_train[x]=scaler1.transform(np.array(X_train[x]).reshape(-1,1))\n",
        "  X_test[x]=scaler1.transform(np.array(X_test[x]).reshape(-1,1))\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCzGsGwLcoIN",
        "outputId": "bf189014-8dee-4ef8-a44e-0c54db1610b5"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(770372, 91)\n",
            "(770372,)\n",
            "(85597, 91)\n",
            "(85597,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TniI5RqG7dOq"
      },
      "source": [
        "logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz78qgHU7dOr"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression #linear_model library all linear model\n",
        "#classifier=LogisticRegression() #classifier becomes a logistic model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLn6bLAa7dOt"
      },
      "source": [
        "#classifier=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "#                 intercept_scaling=1, max_iter=100, multi_class='warn',\n",
        "#                 n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
        "#                 tol=0.0001, verbose=0, warm_start=False)\n",
        "#classifier.fit(X_train,Y_train) #creating a model using fit passing x and y,model is created\n",
        "classifier = LogisticRegression(random_state = 10, class_weight='balanced', max_iter = 1000)\n",
        "classifier.fit(X_train,Y_train)\n",
        "Y_pred=classifier.predict(X_test)  #model predicts y for testing data\n",
        "#print(list(zip(Y_test,Y_pred)))\n",
        "#print(classifier.coef_)\n",
        "#print(classifier.intercept_)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7CCcUM27dOw"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "971dAD0kCp0U",
        "outputId": "435e7bd6-3a66-4343-8a3b-005bc9e2ab73"
      },
      "source": [
        "print('classification report: ')\r\n",
        "print(classification_report(Y_train,classifier.predict(X_train)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    728552\n",
            "           1       0.89      0.96      0.93     41820\n",
            "\n",
            "    accuracy                           0.99    770372\n",
            "   macro avg       0.94      0.98      0.96    770372\n",
            "weighted avg       0.99      0.99      0.99    770372\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqyrCIdP7dOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc6b22e-1d9a-42b7-a02b-48f2245c4b32"
      },
      "source": [
        "cfm=confusion_matrix(Y_test,Y_pred)\n",
        "print(cfm)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[80386   564]\n",
            " [  189  4458]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep5kUQI77dO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9ab209-2d48-4ef6-f003-7c9533667d20"
      },
      "source": [
        "print('classification report: ')\n",
        "print(classification_report(Y_test,Y_pred))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     80950\n",
            "           1       0.89      0.96      0.92      4647\n",
            "\n",
            "    accuracy                           0.99     85597\n",
            "   macro avg       0.94      0.98      0.96     85597\n",
            "weighted avg       0.99      0.99      0.99     85597\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKH3S1TO7dO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc79c6c3-199d-4ca5-85f6-efa050cd6275"
      },
      "source": [
        "acc=accuracy_score(Y_test,Y_pred)\n",
        "print('accuracy of the model is:',acc)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the model is: 0.9912029627206561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oklkF3jI7dO_"
      },
      "source": [
        "Roc curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u46gIubo7dO_"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_D1uMLz7dPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d9b69a-c5bf-4f17-a09a-dd972ad65ad6"
      },
      "source": [
        "fpr, tpr,z = metrics.roc_curve(Y_test, Y_pred)\n",
        "auc = metrics.auc(fpr,tpr)\n",
        "print(auc)\n",
        "print(fpr)\n",
        "print(tpr)\n",
        " "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9761806676765699\n",
            "[0.         0.00696726 1.        ]\n",
            "[0.        0.9593286 1.       ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0knC2PfC7dPG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "1ced5359-b0d7-499e-f28a-4360be447f04"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'True Positive Rate')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gVZfbA8e+h9yKoKwSQKiFIjTSXJoqCCkhXUVEU61pxdWUtP9eylsW2NlREXRERC6i0lSKgUgWpEjqEFQUMClKTnN8f7yS5CcnNALktOZ/nuU/ulDtzZpLMuW+Zd0RVMcYYY/JSLNIBGGOMiW6WKIwxxgRlicIYY0xQliiMMcYEZYnCGGNMUJYojDHGBGWJwhwXEVktIl0iHUe0EJEHROTNCO17rIg8Fol9FzQRuVJEZpzgZ+1vMsQsUcQwEdkiIgdFZL+I7PQuHBVCuU9VTVDVOaHcRwYRKS0iT4rINu8414vIvSIi4dh/LvF0EZHkwHmq+oSqXh+i/YmI3C4iq0TkDxFJFpGPROTsUOzvRInIIyLyn5PZhqq+r6rdfezrmOQYzr/JosoSRey7VFUrAC2AlsDfIhzPcROREnks+gjoBvQEKgJXAcOBF0IQg4hItP0/vADcAdwOnAI0Aj4DLi7oHQX5HYRcJPdtfFJVe8XoC9gCnB8w/TTwZcB0O+BbYC/wA9AlYNkpwNvA/4AU4LOAZZcAy73PfQs0y7lPoAZwEDglYFlLYDdQ0pu+DljrbX86UCdgXQVuBdYDm3M5tm7AIaBWjvltgTSggTc9B3gSWAT8DkzKEVOwczAHeBz4xjuWBsC1Xsz7gE3Ajd665b110oH93qsG8AjwH2+dM73jugbY5p2LkQH7Kwu8452PtcBfgeQ8frcNveNsE+T3PxZ4GfjSi3chUD9g+QvAdu+8LAU6Bix7BJgI/Mdbfj3QBvjOO1c/Af8GSgV8JgH4L/Ar8DPwAHARcAQ46p2TH7x1KwNvedvZATwGFPeWDfXO+XPAHm/ZUGC+t1y8Zb94sa0EmuK+JBz19rcf+Dzn/wFQ3Itro3dOlpLjb8heJ3CtiXQA9jqJX172f5A47x/qBW+6pvdP2BNXcrzAmz7VW/4l8CFQFSgJdPbmt/T+Qdt6/3TXePspncs+ZwE3BMTzDPCa9743sAGIB0oAfwe+DVhXvYvOKUDZXI7tn8DXeRz3VrIu4HO8C1FT3MX8Y7Iu3Pmdgzm4C3qCF2NJ3Lf1+t7FqjNwAGjlrd+FHBd2ck8Ub+CSQnPgMBAfeEzeOY8DVuTcXsB2bwK25vP7H+sdTxsv/veB8QHLhwDVvGX3ADuBMgFxHwX6eOemLNAal1hLeMeyFrjTW78i7qJ/D1DGm26b8xwE7PtT4HXvd3IaLpFn/M6GAqnAX7x9lSV7orgQd4Gv4v0e4oEzAo75sSD/B/fi/g/O8j7bHKgW6f/VWH9FPAB7ncQvz/2D7Md9c1JgJlDFW3Yf8F6O9afjLvxn4L4ZV81lm68C/8gxbx1ZiSTwn/J6YJb3XnDfXjt501OBYQHbKIa76NbxphU4L8ixvRl40cuxbAHeN3Xcxf6fAcua4L5xFg92DgI++2g+5/gz4A7vfRf8JYq4gOWLgMHe+03AhQHLrs+5vYBlI4EF+cQ2FngzYLon8GOQ9VOA5gFxz81n+3cCn3rvLweW5bFe5jnwpk/HJciyAfMuB2Z774cC23JsYyhZieI8IAmXtIrlcszBEsU6oHco/t+K8iva6mTN8eujqhVxF7HGQHVvfh1ggIjszXgBf8YliVrAr6qaksv26gD35PhcLVw1S04fA+1F5AygEy75zAvYzgsB2/gVl0xqBnx+e5Dj2u3FmpszvOW5bWcrrmRQneDnINcYRKSHiCwQkV+99XuSdU792hnw/gCQ0cGgRo79BTv+PeR9/H72hYiMEJG1IvKbdyyVyX4sOY+9kYh84XWM+B14ImD9WrjqHD/q4H4HPwWc99dxJYtc9x1IVWfhqr1eBn4RkdEiUsnnvo8nTuOTJYpCQlW/xn3betabtR33bbpKwKu8qv7TW3aKiFTJZVPbgcdzfK6cqn6Qyz5TgBnAIOAKXAlAA7ZzY47tlFXVbwM3EeSQvgLaikitwJki0hZ3MZgVMDtwndq4KpXd+ZyDY2IQkdK45PcscLqqVgGm4BJcfvH68ROuyim3uHOaCcSJSOKJ7EhEOuLaQAbiSo5VgN/IOhY49nheBX4EGqpqJVxdf8b624F6eewu53a240oU1QPOeyVVTQjymewbVH1RVVvjSoiNcFVK+X7O23f9fNYxx8kSReHyPHCBiDTHNVJeKiIXikhxESnjde+MU9WfcFVDr4hIVREpKSKdvG28AdwkIm29nkDlReRiEamYxz7HAVcD/b33GV4D/iYiCQAiUllEBvg9EFX9Cnex/FhEErxjaOcd16uquj5g9SEi0kREygGPAhNVNS3YOchjt6WA0sAuIFVEegCBXTZ/BqqJSGW/x5HDBNw5qSoiNYHb8lrRO75XgA+8mEt58Q8Wkft97Ksirh1gF1BCRB4C8vtWXhHXeLxfRBoDNwcs+wI4Q0Tu9LotV/SSNrjzcmZGrzHv72sG8C8RqSQixUSkvoh09hE3InKO9/dXEvgD16khPWBfeSUscFWW/xCRht7fbzMRqeZnvyZvligKEVXdBbwLPKSq23ENyg/gLhbbcd/KMn7nV+G+ef+Ia7y+09vGEuAGXNE/BdcgPTTIbifjeujsVNUfAmL5FHgKGO9VY6wCehznIfUDZgPTcG0x/8H1pPlLjvXew5WmduIaWm/3YsjvHGSjqvu8z07AHfsV3vFlLP8R+ADY5FWp5FYdF8yjQDKwGVdimoj75p2X28mqgtmLq1K5DPjcx76m485bEq467hDBq7oARuCOeR/uC8OHGQu8c3MBcCnuPK8HunqLP/J+7hGR7733V+MS7xrcuZyIv6o0cAntDe9zW3HVcM94y94Cmnjn/7NcPjsK9/ubgUt6b+Eay81JkKyaAmNij4jMwTWkRuTu6JMhIjfjGrp9fdM2JlKsRGFMmIjIGSJyrlcVcxauq+mnkY7LmPyELFGIyBgR+UVEVuWxXETkRRHZICIrRKRVqGIxJkqUwvX+2YdrjJ+Ea4cwJqqFrOrJaxzdD7yrqk1zWd4TV9fcE3dz1wuq2jbnesYYYyIrZCUKVZ2L6zufl964JKKqugCo4vXHN8YYE0UiORhXTbL3wkj25v2Uc0URGY4b54Xy5cu3bty4cVgCNMYUXaqQnu5+Br7Pbd7JLs/vMxnvT0RttlKFvawgdbeqnnoi24iJURtVdTQwGiAxMVGXLFkS4YiMMQUlNRUOH856HTmSfTrY/JOZF2zdI0cK9hhLl3avUqWgTJms6Yx5gdN5zTuedUuVVPe+jHDax69S6rdfqPrcI1tPNP5IJoodZL8zNc6bZ4wJgfT08F5s/c470W/KuSlRwt9FtUKFE7wAn8BFvWRJCOsTVHbsgJtvhkGD4Moroal33+Rzj5zwJiOZKCYDt4nIeFxj9m/eHZ3GxDRVOHo08hfgnPNSUwvuGEX8XUArVoTq1UNzAc5tXrGi3OFfFd58E0aMcH+AFxfcY0tClihE5APcQHXVxT0V7GHcQGGo6mu4MXR64u78PYB7DoAxxyUtLbwXWz/7OXLE/c8WlJIl879QlikDlSqF7ltxznklSoT5W7IJbuNGuOEGmD0bunaFN96A+gU35FXIEoWqXp7PcsU9uMbEANVjL4bRUIWRllZwx1ismL8LZZUqoa2qCHyVLFnEvyUbf1auhKVLYfRouP76As/iMdGYXdT4adwL9zfogm7c83MBLV8eTjkltFUVga/ixQv2GI0JqVWr4Pvv4eqroU8f2LQJqoVm/MMinShya9yLhh4XBd245+cCmtG4F46Lctgb94wpTI4cgSeecK/TT4eBA13dY4iSBMRookhJgWeegd9/P7mLeiga9/K7gAY27oX6olyqlH1LNqZQWbgQhg2D1athyBB47jmXJEIsJhPF9Onw5JOurrhs2bwvloGNeyHpqxwwzxr3jDEhtWMHdOzoShFffFGgvZryE5OJ4uhR93PxYmjQILKxGGNMSCUlQaNGULMmfPghdOvmvgWHUUz2p8jo6WLVKsaYQmvvXhg+HBo3hrlz3bzLLgt7koAYLVFkNPZat0FjTKE0ebK7u3rnTrj3XjjnnIiGE5OJwkoUxphC6/rr4a234OyzYdIkSEyMdESWKIwxJuIybuUXcYmhTh247z7XYyYKWKIwxphI2r4dbroJBg+Gq65y76NMTNbyW6IwxsS89HR49VVISIA5c9zNXVHKShTGGBNu69e7toi5c+H8890YTXXrRjqqPFmiMMaYcFuzBlasgDFjYOjQqL9bNyYThXWPNcbEnB9+gOXL4ZproHdvN4hf1aqRjsqXmLzUWonCGBMzDh+GBx90vZkefBAOHXLzYyRJgCUKY4wJne++g5Yt4bHH4IorYNmysAziV9BisurJEoUxJurt2AGdO8Of/gRTpkCPHpGO6ITFdInC2iiMMVFn7Vr3s2ZNmDDBDQkew0kCYjhRWGnCGBNVUlLguuugSROYN8/N69PHPYQmxsVs1ZMlCmNM1Pj0U7jlFti1C/72t4gP4lfQYjJRpKdbtZMxJkpcdx28/Ta0aAFffgmtWkU6ogIXk4nCShTGmIgKHMSvXTto2BBGjHAPhC+ELFEYY8zx2LoVbrzRdXe9+mr3cKFCLiYrcCxRGGPCLj0dXn4ZmjaF+fOznslcBFiJwhhj8rNunRvEb/586N4dXn8dzjwz0lGFjSUKY4zJz7p17n6IsWNddVOUD+JX0CxRGGNMbpYtc4P4XXst9OrlBvGrUiXSUUVETLZRWPdYY0zIHDoEDzzg7oV45JGsQfyKaJKAGE0UVqIwxoTEN9+4+yGefNJVMS1fHpOD+BU0q3oyxhhwg/h17erGaJo+3TVaG8BKFMaYom7NGvezZk34+GNYudKSRA6WKIwxRdOvv7rHkCYkuGdXA1x6KVSoENGwopFVPRljip6PP4Zbb4U9e2DkSGjTJtIRRTVLFMaYomXoUHjnHTd437RprvHaBBWTicK6xxpjjkvgIH4dOkB8PNxzD5SIyUtg2IX0cisiF4nIOhHZICL357K8tojMFpFlIrJCRHr62a6VKIwxvm3e7Bqn333XTQ8fDvfdZ0niOIQsUYhIceBloAfQBLhcRJrkWO3vwARVbQkMBl7xs21LFMaYfKWlwYsvukH8FizIKlWY4xbKEkUbYIOqblLVI8B4oHeOdRSo5L2vDPzPz4YtURhjglq7Fjp2hDvugM6d3ThNQ4dGOqqYFcqyV01ge8B0MtA2xzqPADNE5C9AeeD83DYkIsOB4QC1a9emUiVLFMaYIDZscAP5vfceXHllkRvEr6BFukn4cmCsqsYBPYH3ROSYmFR1tKomqmriqaeeaiUKY8yxli6FMWPc+0svdW0TQ4ZYkigAoUwUO4BaAdNx3rxAw4AJAKr6HVAGqJ7fhi1RGGMyHTwI998PbdvCP/6RNYhfpUrBP2d8C2WiWAw0FJG6IlIK11g9Occ624BuACISj0sUu/LbsHWPNcYA7o7q5s3hqadcG8SyZTaIXwiErI1CVVNF5DZgOlAcGKOqq0XkUWCJqk4G7gHeEJG7cA3bQ1Xz75pgJQpjDDt2QLduUKsWfPWVe29CIqQdiVV1CjAlx7yHAt6vAc493u1aojCmCFu5Es4+2w3i9+mnbsTX8uUjHVWhFpMVOJYojCmCdu+Gq66CZs2yBvG75BJLEmEQk7cmWqIwpghRhY8+gttug5QUePhh13BtwsYShTEmul1zjbsfIjERZs501U4mrCxRGGOiT+Agfp07u+qmO++08ZkixNoojDHRZdMmOP98GDvWTQ8bBiNGWJKIoJhMFHYfhTGFUFoaPP+8q1pavNj+yaNITKZoK1EYU8isWQPXXQcLF8LFF8Nrr0FcXKSjMh5LFMaYyNu8GTZuhHHjYPBgG58pyliiMMZExuLFsHw53HCDK0Vs2gQVK0Y6KpOLmKwEtERhTAw7cMA1TrdrB08+mTWInyWJqGWJwhgTPnPmuK6u//qXK0nYIH4xwaqejDHhkZwMF1wAderArFlujCYTE2KyRGHdY42JIT/84H7GxcGkSbBihSWJGBOTl1srURgTA3btgiuugBYt4Ouv3byePaFcucjGZY6bVT0ZYwqWKowfD7ffDr/9Bv/3f9C+faSjMifBEoUxpmBddRW8/74b4fWttyAhIdIRmZPkO1GISDlVPRDKYPyyRGFMlElPdzfJibj2h9atXYnC/lELhXzbKESkg4isAX70ppuLyCshjyyI9HT7+zMmamzY4B5D+vbbbnrYMLjrLvsnLUT8NGY/B1wI7AFQ1R+ATqEMyg/7GzQmwlJT4dln3SB+y5ZBqVKRjsiEiK+qJ1XdLtnHXkkLTTh+YnE/rXusMRG0ahVcey0sWQK9e8Mrr0CNGpGOyoSIn0SxXUQ6ACoiJYE7gLWhDSt/VqIwJoK2bYOtW13vpoEDbRC/Qs5PorgJeAGoCewAZgC3hDKoYDJKFJYojAmzhQvdzXPDh7v7ITZtggoVIh2VCQM/FThnqeqVqnq6qp6mqkOA+FAHlhdLFMaE2R9/wN13u3shnn4aDh928y1JFBl+EsVLPueFlSUKY8Jg1iw3iN9zz8FNN8H330Pp0pGOyoRZnlVPItIe6ACcKiJ3ByyqBETsMm0lCmPCJDkZLrwQ6tZ1Q3B0inhnRxMhwdooSgEVvHUCB4r/HegfyqCCsURhTIgtWwYtW7pB/D7/HDp3hrJlIx2ViaA8E4Wqfg18LSJjVXVrGGPyxbrHGlPAfv7Z3U09YYJ7bkTnznDRRZGOykQBP72eDojIM0ACkPmEEVU9L2RRBWElCmMKmKobm+mOO2D/fnjsMejQIdJRmSji53v5+7jhO+oC/wdsARaHMCZfLFEYU0CuuMIN5HfWWe4Z1iNHQsmSkY7KRBE/JYpqqvqWiNwRUB0VsURhJQpjCkDgIH7du7uur7feav9YJld+ShRHvZ8/icjFItISOCWEMflif8/GnKCkJDfC65gxbvraa22kVxOUnxLFYyJSGbgHd/9EJeDOkEYVhJUojDlBqakwahQ8/DCUKWM9mYxv+SYKVf3Ce/sb0BVARM4NZVDB43E/LVEYcxxWrIDrroOlS+Gyy+Dll+GMMyIdlYkRwW64Kw4MxI3xNE1VV4nIJcADQFmgZXhCzJ11jzXmOCQnw/bt8NFH0K+fDeJnjkuwy+1bwPVANeBFEfkP8CzwtKr6ShIicpGIrBORDSJyfx7rDBSRNSKyWkTG5bdNK1EY49O338Jrr7n3GYP49e9vScIct2BVT4lAM1VNF5EywE6gvqru8bNhr0TyMnABkAwsFpHJqromYJ2GwN+Ac1U1RURO8xu4JQpj8rB/v+vi+tJLUL++a6wuXRrKl490ZCZGBStRHFHVdABVPQRs8pskPG2ADaq6SVWPAOOB3jnWuQF4WVVTvP38kt9GrURhTBAzZkDTpi5J3HqrDeJnCkSwEkVjEVnhvRegvjctgKpqs3y2XRPYHjCdDLTNsU4jABH5BjfQ4COqOi3nhkRkODAc4PTT6wOWKIw5xvbtcPHFrhQxdy78+c+RjsgUEsESRTieOVECaAh0AeKAuSJytqruDVxJVUcDowEaN07Un3+2RGFMpqVLoXVrqFULpkyBjh1d91djCkieVU+qujXYy8e2dwC1AqbjvHmBkoHJqnpUVTcDSbjEkSerejLGs3MnDBgAiYluGHCACy6wJGEKXCg7mS4GGopIXREpBQwGJudY5zNcaQIRqY6ritrkZ+PWPdYUWarwzjvQpIkbBvyJJ2wQPxNSfu7MPiGqmioitwHTce0PY1R1tYg8CixR1cnesu4isgZIA+7Nr8HcShSmyBs82A0Ffu658Oab0LhxpCMyhZyvRCEiZYHaqrrueDauqlOAKTnmPRTwXoG7vddxsURhipTAQfx69nTtELfcYkVrExb5/pWJyKXAcmCaN91CRHJWIYWNlShMkfPjj+4xpG+95aavuQZuu82ShAkbP39pj+DuidgLoKrLcc+miChLFKbQO3rUtT80bw5r1kCFCpGOyBRRfqqejqrqb5L9tn8NUTz5shKFKRKWL3d3VC9f7obdeOkl+NOfIh2VKaL8JIrVInIFUNwbcuN24NvQhpU3SxSmSNi5070+/hj69o10NKaI81P19Bfc87IPA+Nww41H7HkUGax61hQ68+fDK6+49xddBBs3WpIwUcHP5baxqo5U1XO819+9sZ8iwkoUptDZt881TnfsCM8/D4cPu/nlykU2LmM8fhLFv0RkrYj8Q0SahjwinyxRmEJh+nQ3iN8rr8Add9ggfiYq5ZsoVLUr7sl2u4DXRWSliPw95JHlGY/7aYnCxLzt2+GSS1zJYf58V5qwnk0mCvmq6VfVnar6InAT7p6Kh/L5SMhYojAxTRUWLXLva9WCqVNh2TIbgsNENT833MWLyCMishJ4CdfjKS7kkeXDEoWJOT/95B5D2rZt1iB+559vg/iZqOene+wY4EPgQlX9X4jjyZeVKEzMUYWxY+Huu+HQIXjqKTdOkzExIt9EoartwxHI8bLusSZmDBwIEye6Xk1vvgmNGkU6ImOOS56JQkQmqOpAr8op8E5sv0+4CwkrUZiYkJbmBvArVgwuvRTOOw9uvNG+4ZiYFKxEcYf385JwBHK8LFGYqLV2LQwb5obguOEGuPrqSEdkzEkJ9oS7n7y3t+TydLtbwhNebnG5n5YoTNQ5ehQeewxatIB166By5UhHZEyB8FMOviCXeT0KOhC/LFGYqLRsmXsk6YMPwmWXuVLFwIGRjsqYAhGsjeJmXMmhnoisCFhUEfgm1IHlxxKFiSo//wy7d8Nnn0Hv3pGOxpgCFayNYhwwFXgSuD9g/j5V/TWkUQVhJQoTNebOhZUr4dZb3SB+GzZA2bKRjsqYAhes6klVdQtwK7Av4IWInBL60IKzRGEi5vff3WNIO3eGF1/MGsTPkoQppPIrUVwCLMV1jw18cpEC9UIYV54yShTWy9BExJQprpvr//7nbqB79FEbxM8UenkmClW9xPsZ8cee5pTxjHljwmr7dtf+cNZZ7ga6tm0jHZExYeFnrKdzRaS8936IiIwSkdqhDy13qlbtZMJIFRYscO9r1YIZM9xQ4JYkTBHipwLnVeCAiDQH7gE2Au+FNKogLFGYsPnf/6BPH2jfPmsQv65doVSpyMZlTJj5SRSpqqpAb+DfqvoyrotsxFiiMCGl6sZkatLElSCefdYG8TNFmp/RY/eJyN+Aq4COIlIMKBnasPJmJQoTcv37wyefuF5Nb74JDRpEOiJjIspPiWIQcBi4TlV34p5F8UxIo8qHJQpT4NLSID3dve/TB157DWbNsiRhDP4ehboTeB+oLCKXAIdU9d2QR5ZnPNY11hSwVatc1dJbb7npq66ykV6NCeCn19NAYBEwABgILBSR/qEOLBgrUZgCceQI/N//QatWsHEjVK0a6YiMiUp+2ihGAueo6i8AInIq8BUwMZSB5UUVSviJ2phgli6FoUNdaeKKK+D55+HUUyMdlTFRyc8lt1hGkvDswV/bRkhYY7YpEHv2wN698PnncElUPnLFmKjhJ1FME5HpwAfe9CBgSuhCyp8lCnNCZs92g/jdfjt07w7r10OZMpGOypio56cx+17gdaCZ9xqtqveFOrC847FEYY7Tb7+5xunzzoNXX80axM+ShDG+BHseRUPgWaA+sBIYoao7whVYMJYojG+ffw433QQ7d8KIEa7x2gbxM+a4BCtRjAG+APrhRpB9KSwR5cO6xxrftm+Hfv2gWjU3XtMzz0C5cpGOypiYE6yNoqKqvuG9Xyci34cjID+sRGHypArffQcdOmQN4tehg43PZMxJCPbdvIyItBSRViLSCiibYzpfInKRiKwTkQ0icn+Q9fqJiIpIYn7btDYKk6fkZOjVy908lzGIX5culiSMOUnBShQ/AaMCpncGTCtwXrANi0hx4GXgAiAZWCwik1V1TY71KgJ3AAv9BGyJwhwjPR3eeAPuvRdSU2HUKPjznyMdlTGFRrAHF3U9yW23ATao6iYAERmPG4F2TY71/gE8Bdzrd8OWKEw2/frBZ5+5Xk1vvAH1IvLwRWMKrVA2C9cEtgdMJ3vzMnlVWLVU9ctgGxKR4SKyRESWHD58xBKFcSWHjEH8+vVzCeKrryxJGBMCEes/5A1XPgr3MKSgVHW0qiaqamLJkqUsURR1K1a4hwm94fW1GDIErr/eno9rTIiEMlHsAGoFTMd58zJUBJoCc0RkC9AOmOynQdu6xxZRhw/Dww9D69awdauNzWRMmPgZPVa8Z2U/5E3XFpE2Pra9GGgoInVFpBQwGJicsVBVf1PV6qp6pqqeCSwAeqnqkmAbtcbsImrxYjfK66OPwuWXw9q10LdvpKMypkjw8938FaA9cLk3vQ/XmykoVU0FbgOmA2uBCaq6WkQeFZFeJxgvYImiSEpJgf37YcoUePdddxOdMSYs/AwK2FZVW4nIMgBVTfFKCPlS1SnkGEBQVR/KY90u/rZpiaLImDXLDeJ3xx1uEL+kJBt+w5gI8FOiOOrdE6GQ+TyK9JBGlQ9LFIXc3r1www3QrRu8/nrWIH6WJIyJCD+J4kXgU+A0EXkcmA88EdKogrASRSE3aRI0aQJjxsBf/+oeMGQJwpiIyrfqSVXfF5GlQDdAgD6qujbkkeUZjyWKQmvbNhgwAOLjYfJkSMy3A5wxJgzyTRQiUhs4AHweOE9Vt4UysGCse2whogrz50PHjlC7trtprl07G5/JmCjipzH7S1z7hABlgLrAOiAhhHHlyUoUhci2be5ZEVOnwpw50LkzdOoU6aiMMTn4qXo6O3DaG3bjlpBF5IMlihiXng6vvQb33ecy/4sv2iB+xkQxPyWKbFT1exFpG4pg/O3fEkXM69vXNVpfcAGMHg1nnhnpiIwxQfhpo7g7YLIY0Ar4X8gi8sESRQxKTXWNS8WKwaBB0Ls3DB1q4zMZEwP8NHLHrn0AABnjSURBVAtXDHiVxrVZ9A5lUMFYiSIG/fADtG3rSg/ghuC49lpLEsbEiKAlCu9Gu4qqOiJM8eTLEkUMOXQIHnsMnnoKTjkF/vSnSEdkjDkBeSYKESmhqqkicm44A/LDusfGgEWL4Jpr4Mcf3c9Ro1yyMMbEnGAlikW49ojlIjIZ+Aj4I2Ohqn4S4thyZSWKGPH773DwIEybBhdeGOlojDEnwU+vpzLAHtwzsjPup1AgIokCLFFErRkzYPVquOsuOP98WLfOht8wphAIlihO83o8rSIrQWTQkEYVhJUoolBKCtx9N4wdCwkJcMstLkFYkjCmUAhW218cqOC9Kga8z3hFjCWKKPLJJ24Qv/feg7/9DZYssQRhTCETrETxk6o+GrZIfLISRRTZtg0GD4amTd0DhVq2jHRExpgQCFaiiMpO7pYoIkwVvv7ava9d2z1caOFCSxLGFGLBEkW3sEVxnKx7bIRs3Qo9ekCXLlnJ4s9/hpIlIxqWMSa08rzkquqv4QzELytRREB6Ovz7366hev58eOklNyy4MaZIOO5BAaOBJYow69MHPv/c3Q/x+utQp06kIzLGhJElCpO7o0fdiS5WzI3N1L8/XHWVjc9kTBEUk7X9lihC7PvvoU0b98wIcIni6qstSRhTRFmiMFkOHnT3QrRpAzt3Qq1akY7IGBMFrOrJOAsWuMH7kpLguuvg2WehatVIR2WMiQIxmSise2wI/PGHa5f473/dOE3GGOOJyURhJYoCMm2aG8TvnnugWzc3JHipUpGOyhgTZWLyu7klipO0Z4+rZurRA955B44ccfMtSRhjcmGJoihRhYkT3SB+48bB3/8OixdbgjDGBGVVT0XJtm1wxRXQrJl7dkTz5pGOyBgTA6xEUdipuoH7wN1RPWeO6+FkScIY45MlisJs82bo3t01VGcM4tehA5SIyYKkMSZCLFEURmlp8MIL7jkRCxfCq6/aIH7GmBMWk18t7T6KfPTuDV9+CT17umE47A5rY8xJiMlEYSWKXAQO4nfVVW58piuusPGZjDEnLaTfzUXkIhFZJyIbROT+XJbfLSJrRGSFiMwUEV/jV1uiyGHJEkhMdFVMAIMGwZVXWpIwxhSIkCUKESkOvAz0AJoAl4tIkxyrLQMSVbUZMBF42s+2LVF4Dh6E++6Dtm1h1y57ToQxJiRCWaJoA2xQ1U2qegQYD/QOXEFVZ6vqAW9yARDnZ8OWKIDvvnNdXJ9+2g3it2YNXHJJpKMyxhRCoWyjqAlsD5hOBtoGWX8YMDW3BSIyHBjuplpbogBXmkhPh6++ct1fjTEmRKKiMVtEhgCJQOfclqvqaGC0WzdRi2yimDLFDeJ3771w3nmwdi2ULBnpqIwxhVwoq552AIH9MuO8edmIyPnASKCXqh72s+Ei1z12924YMgQuvhjefz9rED9LEsaYMAjlJXcx0FBE6opIKWAwMDlwBRFpCbyOSxK/+N1wkSlRqML48RAfDxMmwMMPw6JFNoifMSasQlb1pKqpInIbMB0oDoxR1dUi8iiwRFUnA88AFYCPxHXl3KaqvfLbdpFJFNu2ueHAmzeHt96Cs8+OdETGmCIopG0UqjoFmJJj3kMB70/oUWqFOlGowsyZ7ilzdeq4MZrOOaeQH7QxJprFZG1/ob1mbtzoejBdcEHWIH7t2hXiAzbGxAJLFNEgLQ1GjXJVS0uXwuuv2yB+xpioERXdY49XoUsUl14KU6e6G+ZefRXifN13aIwxYRGTiaJQdI89csQ9F6JYMRg61A3kN3iwjc9kjIk6MXnJjfkSxaJF0Lo1vPKKmx440I32aknCGBOFLFGE04EDcM890L49pKRA/fqRjsgYY/IVk1VPMZko5s9390Rs2gQ33ghPPQWVK0c6KmOMyZclinDJeLDQ7NnQpUukozHGGN8sUYTS55+7gfv++lfo2tUNBV4iJk+5MaYIszaKUNi1yz2GtFcv+OCDrEH8LEkYY2JQTCaKqO0eqwrjxrlB/CZOhEcfhYULbRA/Y0xMi8mvuFFboti2Da69Flq2dIP4JSREOiJjjDlp0frdPKioShTp6TB9untfpw7MmwfffGNJwhhTaFiiOBnr17snzV10Ecyd6+a1aRNFARpjzMmzRHEiUlPhmWegWTNYvtxVM9kgfsaYQsraKE7EJZe46qbevd0wHDVqRDggUxgcPXqU5ORkDh06FOlQTAwrU6YMcXFxlCzARyWLqhbYxsJBJFFTUpZQpUqYd3z4sHtGdbFirkdTejoMGGDjM5kCs3nzZipWrEi1atUQ+7syJ0BV2bNnD/v27aNu3brZlonIUlVNPJHtxmTVU9i7xy5YAK1awcsvu+n+/d1AfvbPbArQoUOHLEmYkyIiVKtWrcBLpTGZKMJW9fTHH3DXXdChA+zbBw0bhmnHpqiyJGFOVij+hqyNIi/z5rlB/DZvhltugSefhEqVwrBjY4yJLlaiyEtqqmuT+PprV+VkScIUAdOmTeOss86iQYMG/POf/zxm+datW+nWrRvNmjWjS5cuJCcnAzB79mxatGiR+SpTpgyfffYZ4OrNR44cSaNGjYiPj+fFF18E4Mcff6R9+/aULl2aZ599Ntt+nnvuORISEmjatCmXX355ZlXK5s2badu2LQ0aNGDQoEEcyRgeB5gwYQJNmjQhISGBK664InP+tm3b6N69O/Hx8TRp0oQtW7YA0LFjx8x4a9SoQZ8+fTI/M2fOHFq0aEFCQgKdO3cGYN26ddmOsVKlSjz//POZn3nppZdo3LgxCQkJ/PWvfwVgy5YtlC1bNvMzN910U+b6R44cYfjw4TRq1IjGjRvz8ccfBz3HAPfddx9NmzaladOmfPjhh75+pwVCVWPqBa01LU1D49NPVZ94Imv66NEQ7ciYY61Zsyai+09NTdV69erpxo0b9fDhw9qsWTNdvXp1tnX69++vY8eOVVXVmTNn6pAhQ47Zzp49e7Rq1ar6xx9/qKrqmDFj9KqrrtI07x/3559/zvy5aNEifeCBB/SZZ57J/HxycrKeeeaZeuDAAVVVHTBggL799tuZ7z/44ANVVb3xxhv1lVdeUVXVpKQkbdGihf7666/Z9qGq2rlzZ50xY4aqqu7bty8zrkB9+/bVd955R1VVU1JSND4+Xrdu3XrMtgLP1emnn65btmxRVdVZs2Zpt27d9NChQ9k+s3nzZk1ISDjm86qqDz30kI4cOVJVVdPS0nTXrl2qmvc5/uKLL/T888/Xo0eP6v79+zUxMVF/++23XLed298SsERP8Lobk1VPBd6Y/fPP8Je/wEcfuUbre+5x4zPZIH4mQu68092iU5BatICAL8DHWLRoEQ0aNKBevXoADB48mEmTJtGkSZPMddasWcOoUaMA6Nq1a7Zv4RkmTpxIjx49KFeuHACvvvoq48aNo5j3j3vaaadl/jzttNP48ssvj9lGamoqBw8epGTJkhw4cIAaNWqgqsyaNYtx48YBcM011/DII49w880388Ybb3DrrbdStWrVbPtYs2YNqampXHDBBQBUqFDhmH39/vvvzJo1i7fffhuAcePG0bdvX2rXrp1tW4FmzpxJ/fr1qVOnTuYx3n///ZQuXTrPz+Q0ZswYfvzxRwCKFStG9erVM2PO7RyvWbOGTp06UaJECUqUKEGzZs2YNm0aAwcOzHdfJysmq54KjCq89x40aQKTJsHjj7seTjaInymCduzYQa1atTKn4+Li2LFjR7Z1mjdvzieffALAp59+yr59+9izZ0+2dcaPH8/ll1+eOb1x40Y+/PBDEhMT6dGjB+vXrw8aR82aNRkxYgS1a9fmjDPOoHLlynTv3p09e/ZQpUoVSnhf4ALjS0pKIikpiXPPPZd27doxbdq0zPlVqlShb9++tGzZknvvvZe0tLRs+/vss8/o1q0blbzq5aSkJFJSUujSpQutW7fm3XffPSbGnMeYlJTEvHnzaNu2LZ07d2bx4sWZyzZv3kzLli3p3Lkz8+bNA2Dv3r0APPjgg7Rq1YoBAwbw888/Bz3HzZs3Z9q0aRw4cIDdu3cze/Zstm/fHvRcFpSY+8pcoA3627bB9ddDYqK7u7px4wLcuDEnLtg3/0h69tlnue222xg7diydOnWiZs2aFA9oNPzpp59YuXIlF154Yea8w4cPU6ZMGZYsWcInn3zCddddl3nBzE1KSgqTJk1i8+bNVKlShQEDBvCf//yHiy66KM/PpKamsn79eubMmUNycjKdOnVi5cqVpKamMm/ePJYtW0bt2rUZNGgQY8eOZdiwYZmf/eCDD7j++uuzbWvp0qXMnDmTgwcP0r59e9q1a0ejRo0A17YwefJknnzyyWyf+fXXX1mwYAGLFy9m4MCBbNq0iTPOOINt27ZRrVo1li5dSp8+fVi9ejWpqakkJyfToUMHRo0axahRoxgxYgTvvfdenue4e/fuLF68mA4dOnDqqafSvn37bOc+lIpeiSI9HaZOde/r1HED+M2da0nCFHk1a9bM9g01OTmZmjVrZlunRo0afPLJJyxbtozHH38cgCoBd79OmDCByy67LNtdwXFxcfTt2xeAyy67jBUrVgSN46uvvqJu3bqceuqplCxZkr59+/Ltt99SrVo19u7dS2pq6jHxxcXF0atXL0qWLEndunVp1KgR69evJy4ujhYtWlCvXj1KlChBnz59+P777zP3tXv3bhYtWsTFF1+cLd4LL7yQ8uXLU716dTp16sQPP/yQuXzq1Km0atWK008//ZhjFBHatGlDsWLF2L17N6VLl6ZatWoAtG7dmvr165OUlES1atUoV65c5nkZMGBAZlzBzvHIkSNZvnw5//3vf1HVzOQVajGXKE6qRJGU5B5D2rOn680ErjQR8TFBjIm8c845h/Xr17N582aOHDnC+PHj6dWrV7Z1du/eTXp6OgBPPvkk1113XbblH3zwQbYqGYA+ffowe/ZsAL7++ut8L261a9dmwYIFHDhwAFVl5syZxMfHIyJ07dqViRMnAvDOO+/Qu3fvzH3MmTMnM8akpCTq1avHOeecw969e9m1axcAs2bNytbmMnHiRC655BLKlCmTOa93797Mnz+f1NRUDhw4wMKFC4mPj/d9jElJSRw5coTq1auza9euzKquTZs2sX79eurVq4eIcOmll2bGPHPmzMy48jrHaWlpmdV8K1asYMWKFXTv3j3ouSwwJ9oKHqlXsWKtc23lD+roUdV//lO1dGnVKlVU335bNT39+LdjTAhFuteTquqXX36pDRs21Hr16uljjz2mqqoPPvigTpo0SVVVP/roI23QoIE2bNhQhw0bltnLR9X18KlRo0Zm76YMKSkp2rNnT23atKm2a9dOly9frqqqP/30k9asWVMrVqyolStX1po1a2b24nnooYf0rLPO0oSEBB0yZEjmfjZu3KjnnHOO1q9fX/v37585Pz09Xe+66y6Nj4/Xpk2bZvaMUlWdMWOGnn322dq0aVO95ppr9PDhw5nLOnfurFOnTj3mPDz99NMaHx+vCQkJ+txzz2XO379/v55yyim6d+/ebOsfPnxYr7zySk1ISNCWLVvqzJkzVVV14sSJ2qRJE23evLm2bNlSJ0+enPmZLVu2aMeOHfXss8/W8847L7OXVV7n+ODBgxofH6/x8fHatm1bXbZsWZ6/x4Lu9RRzYz2VKJGoqalLju9DF14IM2ZA377unog//Sk0wRlzEtauXZvtm6sxJyq3v6WTGeup8DZmHzrkbpgrXhyGD3evfv1CGpsxxhRGMddG4cs337hO4xmD+PXrZ0nCGGNOUMwliqAliv374fbb3UOEDh0CK8abGBNrVcEm+oTibyjmEkWevv4amjaFf/8bbrsNVq0C725MY2JBmTJl2LNnjyULc8LUex5FYC+uglC42ijKlXOjvp57btjiMaagxMXFkZycnNmV05gTkfGEu4IUc72eSpdO1MOHvV5Pn3wCP/4IDzzgptPS7J4IY4zJRdQ+4U5ELhKRdSKyQUTuz2V5aRH50Fu+UETOzH+bwM6d7ilz/frBp59CxlDDliSMMabAhSxRiEhx4GWgB9AEuFxEmuRYbRiQoqoNgOeAp/LbbtW0Pa6R+osv3MOEvv3WBvEzxpgQCmWJog2wQVU3qeoRYDzQO8c6vYF3vPcTgW6Sz3P8aqRudY3WP/wA99/v7pUwxhgTMqFszK4JBI6Bmwy0zWsdVU0Vkd+AasDuwJVEZDgw3Js8LPPnr7JB/ACoTo5zVYTZuchi5yKLnYssZ53oB2Oi15OqjgZGA4jIkhNtkCls7FxksXORxc5FFjsXWUTkOMc+yhLKqqcdQK2A6ThvXq7riEgJoDKwB2OMMVEjlIliMdBQROqKSClgMDA5xzqTgWu89/2BWRpr/XWNMaaQC1nVk9fmcBswHSgOjFHV1SLyKG6428nAW8B7IrIB+BWXTPIzOlQxxyA7F1nsXGSxc5HFzkWWEz4XMXfDnTHGmPAqPGM9GWOMCQlLFMYYY4KK2kQRiuE/YpWPc3G3iKwRkRUiMlNE6kQiznDI71wErNdPRFRECm3XSD/nQkQGen8bq0VkXLhjDBcf/yO1RWS2iCzz/k96RiLOUBORMSLyi4isymO5iMiL3nlaISKtfG34RJ+hGsoXrvF7I1APKAX8ADTJsc4twGve+8HAh5GOO4LnoitQznt/c1E+F956FYG5wAIgMdJxR/DvoiGwDKjqTZ8W6bgjeC5GAzd775sAWyIdd4jORSegFbAqj+U9gamAAO2AhX62G60lipAM/xGj8j0XqjpbVQ94kwtw96wURn7+LgD+gRs37FA4gwszP+fiBuBlVU0BUNVfwhxjuPg5FwpU8t5XBv4XxvjCRlXn4nqQ5qU38K46C4AqInJGftuN1kSR2/AfNfNaR1VTgYzhPwobP+ci0DDcN4bCKN9z4RWla6nql+EMLAL8/F00AhqJyDciskBELgpbdOHl51w8AgwRkWRgCvCX8IQWdY73egLEyBAexh8RGQIkAp0jHUskiEgxYBQwNMKhRIsSuOqnLrhS5lwROVtV90Y0qsi4HBirqv8Skfa4+7eaqmp6pAOLBdFaorDhP7L4OReIyPnASKCXqh4OU2zhlt+5qAg0BeaIyBZcHezkQtqg7efvIhmYrKpHVXUzkIRLHIWNn3MxDJgAoKrfAWVwAwYWNb6uJzlFa6Kw4T+y5HsuRKQl8DouSRTWemjI51yo6m+qWl1Vz1TVM3HtNb1U9YQHQ4tifv5HPsOVJhCR6riqqE3hDDJM/JyLbUA3ABGJxyWKovjM2cnA1V7vp3bAb6r6U34fisqqJw3d8B8xx+e5eAaoAHzktedvU9VeEQs6RHyeiyLB57mYDnQXkTVAGnCvqha6UrfPc3EP8IaI3IVr2B5aGL9YisgHuC8H1b32mIeBkgCq+hqufaYnsAE4AFzra7uF8FwZY4wpQNFa9WSMMSZKWKIwxhgTlCUKY4wxQVmiMMYYE5QlCmOMMUFZojBRSUTSRGR5wOvMIOvuL4D9jRWRzd6+vvfu3j3ebbwpIk289w/kWPbtycbobSfjvKwSkc9FpEo+67corCOlmvCx7rEmKonIflWtUNDrBtnGWOALVZ0oIt2BZ1W12Uls76Rjym+7IvIOkKSqjwdZfyhuBN3bCjoWU3RYicLEBBGp4D1r43sRWSkix4waKyJniMjcgG/cHb353UXkO++zH4lIfhfwuUAD77N3e9taJSJ3evPKi8iXIvKDN3+QN3+OiCSKyD+Bsl4c73vL9ns/x4vIxQExjxWR/iJSXESeEZHF3nMCbvRxWr7DG9BNRNp4x7hMRL4VkbO8u5QfBQZ5sQzyYh8jIou8dXMbfdeY7CI9frq97JXbC3cn8XLv9SluFIFK3rLquDtLM0rE+72f9wAjvffFcWM/Vcdd+Mt78+8DHsplf2OB/t77AcBCoDWwEiiPu/N9NdAS6Ae8EfDZyt7POXjPv8iIKWCdjBgvA97x3pfCjeRZFhgO/N2bXxpYAtTNJc79Acf3EXCRN10JKOG9Px/42Hs/FPh3wOefAIZ476vgxn8qH+nft72i+xWVQ3gYAxxU1RYZEyJSEnhCRDoB6bhv0qcDOwM+sxgY4637maouF5HOuAfVfOMNb1IK9008N8+IyN9xYwANw40N9Kmq/uHF8AnQEZgG/EtEnsJVV807juOaCrwgIqWBi4C5qnrQq+5qJiL9vfUq4wbw25zj82VFZLl3/GuB/was/46INMQNUVEyj/13B3qJyAhvugxQ29uWMbmyRGFixZXAqUBrVT0qbnTYMoErqOpcL5FcDIwVkVFACvBfVb3cxz7uVdWJGRMi0i23lVQ1SdxzL3oCj4nITFV91M9BqOohEZkDXAgMwj1kB9wTx/6iqtPz2cRBVW0hIuVwYxvdCryIe1jTbFW9zGv4n5PH5wXop6rr/MRrDFgbhYkdlYFfvCTRFTjmueDinhX+s6q+AbyJeyTkAuBcEclocygvIo187nMe0EdEyolIeVy10TwRqQEcUNX/4AZkzO25w0e9kk1uPsQNxpZROgF30b854zMi0sjbZ67UPdHwduAeyRpmP2O46KEBq+7DVcFlmA78RbzilbiRh40JyhKFiRXvA4kishK4Gvgxl3W6AD+IyDLct/UXVHUX7sL5gYiswFU7NfazQ1X9Htd2sQjXZvGmqi4DzgYWeVVADwOP5fLx0cCKjMbsHGbgHi71lbpHd4JLbGuA70VkFW7Y+KAlfi+WFbiH8jwNPOkde+DnZgNNMhqzcSWPkl5sq71pY4Ky7rHGGGOCshKFMcaYoCxRGGOMCcoShTHGmKAsURhjjAnKEoUxxpigLFEYY4wJyhKFMcaYoP4fQmDuxntNS40AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "T3FhnAr_jLUH",
        "outputId": "a76afe74-fa53-4773-da40-ef3e5d920c4e"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "probs = classifier.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "precision, recall, threshold = precision_recall_curve(Y_test, preds)\n",
        "\n",
        "plt.title(\"Precision-Recall vs Threshold Chart\")\n",
        "plt.plot(threshold, precision[: -1], \"b--\", label=\"Precision\")\n",
        "plt.plot(threshold, recall[: -1], \"r--\", label=\"Recall\")\n",
        "plt.ylabel(\"Precision, Recall\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.ylim([0,1]) "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_3Lw9fDjAqM",
        "outputId": "5a18bec3-f9ab-49ad-b566-8161dbff3748"
      },
      "source": [
        "threshold = 0.7\n",
        "pred = np.where(classifier.predict_proba(X_test)[:,1] >= threshold, 1, 0)\n",
        "labels = [1, 0]\n",
        "con_mat2 = confusion_matrix(Y_test, pred, labels = labels )\n",
        "print(con_mat2)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "actual = Y_test\n",
        "predicted = pred\n",
        "print ('Accuracy Score :',accuracy_score(actual, predicted)) \n",
        "print ('Report : ')\n",
        "print (classification_report(actual, predicted))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4387   260]\n",
            " [  236 80714]]\n",
            "Accuracy Score : 0.9942054043950138\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     80950\n",
            "           1       0.95      0.94      0.95      4647\n",
            "\n",
            "    accuracy                           0.99     85597\n",
            "   macro avg       0.97      0.97      0.97     85597\n",
            "weighted avg       0.99      0.99      0.99     85597\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Muup6y0l_yWN"
      },
      "source": [
        "Ramdom Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mby2WwRlIXF",
        "outputId": "10578104-9dad-49da-fa4b-81ade843a68b"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(random_state=50, n_estimators= 200, oob_score=True, class_weight={0: 1, 1: 10}, max_features=10,max_depth=10 )\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "score = model.score(X_test, Y_test)\n",
        "\n",
        "print(\"Training\")\n",
        "print(\"Accuracy {0:.2f}%\".format(100*accuracy_score(model.predict(X_train), Y_train)))\n",
        "print(confusion_matrix(Y_train, model.predict(X_train)))\n",
        "print(classification_report(Y_train, model.predict(X_train)))\n",
        "\n",
        "print(\"testing\")\n",
        "print(\"Accuracy {0:.2f}%\".format(100*accuracy_score(predictions, Y_test)))\n",
        "print(confusion_matrix(Y_test, predictions))\n",
        "print(classification_report(Y_test, predictions))\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "Accuracy 99.03%\n",
            "[[722894   5658]\n",
            " [  1813  40007]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99    728552\n",
            "           1       0.88      0.96      0.91     41820\n",
            "\n",
            "    accuracy                           0.99    770372\n",
            "   macro avg       0.94      0.97      0.95    770372\n",
            "weighted avg       0.99      0.99      0.99    770372\n",
            "\n",
            "testing\n",
            "Accuracy 98.89%\n",
            "[[80257   693]\n",
            " [  260  4387]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     80950\n",
            "           1       0.86      0.94      0.90      4647\n",
            "\n",
            "    accuracy                           0.99     85597\n",
            "   macro avg       0.93      0.97      0.95     85597\n",
            "weighted avg       0.99      0.99      0.99     85597\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPiHs5aCuDtn"
      },
      "source": [
        "!set GPU=1"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtBlawfk_1h2"
      },
      "source": [
        "Nueral network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rG341mwlIOL"
      },
      "source": [
        "# If you wish to use Tensorflow 1.X run the following line and then restart runtime\n",
        "# %tensorflow_version 1.x \n",
        "# You'll need to change your import statements from tensorflow.keras to keras\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout,BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model = Sequential()\n",
        "model.add(Dense(100,input_dim=91 ,activation='relu',kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(100,activation='relu',kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(100,activation='relu',kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdHV1cytlIJw",
        "outputId": "070c80eb-452d-490a-cb9b-1aa26e3b8922"
      },
      "source": [
        "# Start Training Our Classifier \n",
        "#batch_size = 256\n",
        "#epochs = 100\n",
        "INIT_LR = 0.00001\n",
        "\n",
        "batch_size = 512\n",
        "epochs = 500\n",
        "\n",
        "class_weight = {0: 1,\n",
        "                1: 4}\n",
        "\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / epochs)\n",
        "model.compile(optimizer= opt,loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train,\n",
        "                    Y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                     class_weight=class_weight,\n",
        "                    validation_data = (X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1505/1505 [==============================] - 12s 6ms/step - loss: 4.3071 - accuracy: 0.4767 - val_loss: 3.9943 - val_accuracy: 0.0558\n",
            "Epoch 2/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 3.9268 - accuracy: 0.5151 - val_loss: 3.5355 - val_accuracy: 0.0803\n",
            "Epoch 3/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 3.6116 - accuracy: 0.5547 - val_loss: 3.1811 - val_accuracy: 0.2448\n",
            "Epoch 4/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 3.3305 - accuracy: 0.5922 - val_loss: 2.9017 - val_accuracy: 0.5140\n",
            "Epoch 5/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 3.0828 - accuracy: 0.6298 - val_loss: 2.6608 - val_accuracy: 0.7574\n",
            "Epoch 6/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 2.8616 - accuracy: 0.6651 - val_loss: 2.4523 - val_accuracy: 0.8800\n",
            "Epoch 7/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 2.6593 - accuracy: 0.6999 - val_loss: 2.2685 - val_accuracy: 0.9260\n",
            "Epoch 8/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 2.4799 - accuracy: 0.7304 - val_loss: 2.1053 - val_accuracy: 0.9404\n",
            "Epoch 9/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 2.3156 - accuracy: 0.7600 - val_loss: 1.9566 - val_accuracy: 0.9439\n",
            "Epoch 10/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 2.1629 - accuracy: 0.7875 - val_loss: 1.8206 - val_accuracy: 0.9452\n",
            "Epoch 11/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 2.0256 - accuracy: 0.8121 - val_loss: 1.6979 - val_accuracy: 0.9455\n",
            "Epoch 12/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 1.9012 - accuracy: 0.8334 - val_loss: 1.5836 - val_accuracy: 0.9456\n",
            "Epoch 13/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 1.7891 - accuracy: 0.8517 - val_loss: 1.4784 - val_accuracy: 0.9456\n",
            "Epoch 14/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 1.6827 - accuracy: 0.8657 - val_loss: 1.3809 - val_accuracy: 0.9456\n",
            "Epoch 15/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 1.5874 - accuracy: 0.8766 - val_loss: 1.2918 - val_accuracy: 0.9456\n",
            "Epoch 16/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 1.4990 - accuracy: 0.8859 - val_loss: 1.2088 - val_accuracy: 0.9456\n",
            "Epoch 17/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 1.4173 - accuracy: 0.8923 - val_loss: 1.1321 - val_accuracy: 0.9456\n",
            "Epoch 18/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 1.3395 - accuracy: 0.8972 - val_loss: 1.0589 - val_accuracy: 0.9456\n",
            "Epoch 19/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 1.2641 - accuracy: 0.9010 - val_loss: 0.9922 - val_accuracy: 0.9457\n",
            "Epoch 20/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 1.1939 - accuracy: 0.9038 - val_loss: 0.9287 - val_accuracy: 0.9461\n",
            "Epoch 21/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 1.1372 - accuracy: 0.9036 - val_loss: 0.8681 - val_accuracy: 0.9473\n",
            "Epoch 22/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 1.0695 - accuracy: 0.9071 - val_loss: 0.8106 - val_accuracy: 0.9491\n",
            "Epoch 23/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 1.0138 - accuracy: 0.9081 - val_loss: 0.7578 - val_accuracy: 0.9514\n",
            "Epoch 24/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.9574 - accuracy: 0.9095 - val_loss: 0.7063 - val_accuracy: 0.9540\n",
            "Epoch 25/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.9047 - accuracy: 0.9108 - val_loss: 0.6563 - val_accuracy: 0.9561\n",
            "Epoch 26/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.8509 - accuracy: 0.9138 - val_loss: 0.6105 - val_accuracy: 0.9586\n",
            "Epoch 27/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.8027 - accuracy: 0.9161 - val_loss: 0.5665 - val_accuracy: 0.9613\n",
            "Epoch 28/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.7522 - accuracy: 0.9199 - val_loss: 0.5250 - val_accuracy: 0.9636\n",
            "Epoch 29/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.7100 - accuracy: 0.9234 - val_loss: 0.4865 - val_accuracy: 0.9659\n",
            "Epoch 30/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.6676 - accuracy: 0.9271 - val_loss: 0.4508 - val_accuracy: 0.9686\n",
            "Epoch 31/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.6249 - accuracy: 0.9321 - val_loss: 0.4169 - val_accuracy: 0.9712\n",
            "Epoch 32/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.5871 - accuracy: 0.9365 - val_loss: 0.3864 - val_accuracy: 0.9736\n",
            "Epoch 33/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.5489 - accuracy: 0.9408 - val_loss: 0.3562 - val_accuracy: 0.9758\n",
            "Epoch 34/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.5156 - accuracy: 0.9450 - val_loss: 0.3291 - val_accuracy: 0.9783\n",
            "Epoch 35/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.4798 - accuracy: 0.9504 - val_loss: 0.3047 - val_accuracy: 0.9806\n",
            "Epoch 36/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.4499 - accuracy: 0.9540 - val_loss: 0.2814 - val_accuracy: 0.9826\n",
            "Epoch 37/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.4170 - accuracy: 0.9582 - val_loss: 0.2590 - val_accuracy: 0.9845\n",
            "Epoch 38/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.3926 - accuracy: 0.9613 - val_loss: 0.2406 - val_accuracy: 0.9858\n",
            "Epoch 39/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.3650 - accuracy: 0.9652 - val_loss: 0.2230 - val_accuracy: 0.9869\n",
            "Epoch 40/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.3409 - accuracy: 0.9681 - val_loss: 0.2062 - val_accuracy: 0.9883\n",
            "Epoch 41/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.3208 - accuracy: 0.9712 - val_loss: 0.1929 - val_accuracy: 0.9888\n",
            "Epoch 42/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.2995 - accuracy: 0.9736 - val_loss: 0.1800 - val_accuracy: 0.9897\n",
            "Epoch 43/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.2791 - accuracy: 0.9764 - val_loss: 0.1693 - val_accuracy: 0.9900\n",
            "Epoch 44/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.2661 - accuracy: 0.9779 - val_loss: 0.1591 - val_accuracy: 0.9907\n",
            "Epoch 45/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.2528 - accuracy: 0.9795 - val_loss: 0.1498 - val_accuracy: 0.9914\n",
            "Epoch 46/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.2363 - accuracy: 0.9810 - val_loss: 0.1420 - val_accuracy: 0.9919\n",
            "Epoch 47/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.2260 - accuracy: 0.9828 - val_loss: 0.1353 - val_accuracy: 0.9920\n",
            "Epoch 48/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.2162 - accuracy: 0.9838 - val_loss: 0.1285 - val_accuracy: 0.9924\n",
            "Epoch 49/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.2041 - accuracy: 0.9848 - val_loss: 0.1229 - val_accuracy: 0.9926\n",
            "Epoch 50/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1929 - accuracy: 0.9863 - val_loss: 0.1173 - val_accuracy: 0.9930\n",
            "Epoch 51/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1877 - accuracy: 0.9864 - val_loss: 0.1116 - val_accuracy: 0.9936\n",
            "Epoch 52/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.1804 - accuracy: 0.9874 - val_loss: 0.1076 - val_accuracy: 0.9937\n",
            "Epoch 53/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.1725 - accuracy: 0.9879 - val_loss: 0.1033 - val_accuracy: 0.9939\n",
            "Epoch 54/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1661 - accuracy: 0.9888 - val_loss: 0.0996 - val_accuracy: 0.9940\n",
            "Epoch 55/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1608 - accuracy: 0.9892 - val_loss: 0.0956 - val_accuracy: 0.9945\n",
            "Epoch 56/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1530 - accuracy: 0.9900 - val_loss: 0.0927 - val_accuracy: 0.9943\n",
            "Epoch 57/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.1458 - accuracy: 0.9908 - val_loss: 0.0891 - val_accuracy: 0.9946\n",
            "Epoch 58/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1424 - accuracy: 0.9908 - val_loss: 0.0862 - val_accuracy: 0.9947\n",
            "Epoch 59/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1406 - accuracy: 0.9912 - val_loss: 0.0837 - val_accuracy: 0.9947\n",
            "Epoch 60/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1342 - accuracy: 0.9918 - val_loss: 0.0808 - val_accuracy: 0.9948\n",
            "Epoch 61/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.1279 - accuracy: 0.9919 - val_loss: 0.0786 - val_accuracy: 0.9949\n",
            "Epoch 62/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1241 - accuracy: 0.9925 - val_loss: 0.0763 - val_accuracy: 0.9950\n",
            "Epoch 63/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1244 - accuracy: 0.9925 - val_loss: 0.0739 - val_accuracy: 0.9952\n",
            "Epoch 64/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1219 - accuracy: 0.9930 - val_loss: 0.0721 - val_accuracy: 0.9951\n",
            "Epoch 65/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.1202 - accuracy: 0.9928 - val_loss: 0.0700 - val_accuracy: 0.9953\n",
            "Epoch 66/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.1151 - accuracy: 0.9932 - val_loss: 0.0676 - val_accuracy: 0.9954\n",
            "Epoch 67/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.1102 - accuracy: 0.9935 - val_loss: 0.0667 - val_accuracy: 0.9954\n",
            "Epoch 68/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.1094 - accuracy: 0.9935 - val_loss: 0.0649 - val_accuracy: 0.9954\n",
            "Epoch 69/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.1051 - accuracy: 0.9941 - val_loss: 0.0629 - val_accuracy: 0.9956\n",
            "Epoch 70/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.1066 - accuracy: 0.9937 - val_loss: 0.0619 - val_accuracy: 0.9955\n",
            "Epoch 71/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.1025 - accuracy: 0.9943 - val_loss: 0.0601 - val_accuracy: 0.9956\n",
            "Epoch 72/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0995 - accuracy: 0.9942 - val_loss: 0.0586 - val_accuracy: 0.9957\n",
            "Epoch 73/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.1002 - accuracy: 0.9943 - val_loss: 0.0573 - val_accuracy: 0.9959\n",
            "Epoch 74/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0975 - accuracy: 0.9944 - val_loss: 0.0558 - val_accuracy: 0.9960\n",
            "Epoch 75/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0927 - accuracy: 0.9946 - val_loss: 0.0549 - val_accuracy: 0.9959\n",
            "Epoch 76/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0922 - accuracy: 0.9948 - val_loss: 0.0539 - val_accuracy: 0.9960\n",
            "Epoch 77/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0909 - accuracy: 0.9949 - val_loss: 0.0525 - val_accuracy: 0.9961\n",
            "Epoch 78/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0908 - accuracy: 0.9948 - val_loss: 0.0522 - val_accuracy: 0.9960\n",
            "Epoch 79/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0881 - accuracy: 0.9950 - val_loss: 0.0509 - val_accuracy: 0.9961\n",
            "Epoch 80/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0883 - accuracy: 0.9949 - val_loss: 0.0499 - val_accuracy: 0.9961\n",
            "Epoch 81/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0859 - accuracy: 0.9951 - val_loss: 0.0488 - val_accuracy: 0.9962\n",
            "Epoch 82/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0851 - accuracy: 0.9951 - val_loss: 0.0483 - val_accuracy: 0.9962\n",
            "Epoch 83/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0827 - accuracy: 0.9952 - val_loss: 0.0470 - val_accuracy: 0.9963\n",
            "Epoch 84/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0828 - accuracy: 0.9955 - val_loss: 0.0468 - val_accuracy: 0.9963\n",
            "Epoch 85/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0830 - accuracy: 0.9954 - val_loss: 0.0456 - val_accuracy: 0.9964\n",
            "Epoch 86/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0801 - accuracy: 0.9955 - val_loss: 0.0449 - val_accuracy: 0.9964\n",
            "Epoch 87/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0816 - accuracy: 0.9953 - val_loss: 0.0442 - val_accuracy: 0.9964\n",
            "Epoch 88/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0793 - accuracy: 0.9956 - val_loss: 0.0435 - val_accuracy: 0.9965\n",
            "Epoch 89/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0790 - accuracy: 0.9955 - val_loss: 0.0431 - val_accuracy: 0.9965\n",
            "Epoch 90/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0771 - accuracy: 0.9958 - val_loss: 0.0427 - val_accuracy: 0.9965\n",
            "Epoch 91/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0760 - accuracy: 0.9959 - val_loss: 0.0420 - val_accuracy: 0.9966\n",
            "Epoch 92/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0759 - accuracy: 0.9960 - val_loss: 0.0415 - val_accuracy: 0.9967\n",
            "Epoch 93/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0779 - accuracy: 0.9957 - val_loss: 0.0410 - val_accuracy: 0.9967\n",
            "Epoch 94/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0762 - accuracy: 0.9959 - val_loss: 0.0402 - val_accuracy: 0.9968\n",
            "Epoch 95/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0738 - accuracy: 0.9961 - val_loss: 0.0398 - val_accuracy: 0.9969\n",
            "Epoch 96/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0729 - accuracy: 0.9962 - val_loss: 0.0401 - val_accuracy: 0.9968\n",
            "Epoch 97/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0734 - accuracy: 0.9961 - val_loss: 0.0390 - val_accuracy: 0.9969\n",
            "Epoch 98/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0706 - accuracy: 0.9962 - val_loss: 0.0389 - val_accuracy: 0.9969\n",
            "Epoch 99/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0710 - accuracy: 0.9962 - val_loss: 0.0387 - val_accuracy: 0.9970\n",
            "Epoch 100/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0712 - accuracy: 0.9962 - val_loss: 0.0381 - val_accuracy: 0.9970\n",
            "Epoch 101/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0699 - accuracy: 0.9964 - val_loss: 0.0381 - val_accuracy: 0.9970\n",
            "Epoch 102/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0709 - accuracy: 0.9963 - val_loss: 0.0377 - val_accuracy: 0.9970\n",
            "Epoch 103/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0673 - accuracy: 0.9965 - val_loss: 0.0375 - val_accuracy: 0.9969\n",
            "Epoch 104/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0697 - accuracy: 0.9963 - val_loss: 0.0371 - val_accuracy: 0.9970\n",
            "Epoch 105/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0690 - accuracy: 0.9965 - val_loss: 0.0370 - val_accuracy: 0.9971\n",
            "Epoch 106/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0703 - accuracy: 0.9963 - val_loss: 0.0367 - val_accuracy: 0.9970\n",
            "Epoch 107/500\n",
            "1505/1505 [==============================] - 7s 4ms/step - loss: 0.0693 - accuracy: 0.9963 - val_loss: 0.0362 - val_accuracy: 0.9971\n",
            "Epoch 108/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0360 - val_accuracy: 0.9971\n",
            "Epoch 109/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0692 - accuracy: 0.9964 - val_loss: 0.0359 - val_accuracy: 0.9971\n",
            "Epoch 110/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0678 - accuracy: 0.9965 - val_loss: 0.0357 - val_accuracy: 0.9971\n",
            "Epoch 111/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0682 - accuracy: 0.9964 - val_loss: 0.0356 - val_accuracy: 0.9972\n",
            "Epoch 112/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0681 - accuracy: 0.9965 - val_loss: 0.0352 - val_accuracy: 0.9972\n",
            "Epoch 113/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0663 - accuracy: 0.9966 - val_loss: 0.0354 - val_accuracy: 0.9971\n",
            "Epoch 114/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0346 - val_accuracy: 0.9972\n",
            "Epoch 115/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0671 - accuracy: 0.9966 - val_loss: 0.0348 - val_accuracy: 0.9973\n",
            "Epoch 116/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0658 - accuracy: 0.9966 - val_loss: 0.0346 - val_accuracy: 0.9972\n",
            "Epoch 117/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0659 - accuracy: 0.9967 - val_loss: 0.0345 - val_accuracy: 0.9972\n",
            "Epoch 118/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0659 - accuracy: 0.9965 - val_loss: 0.0343 - val_accuracy: 0.9972\n",
            "Epoch 119/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0645 - accuracy: 0.9967 - val_loss: 0.0340 - val_accuracy: 0.9972\n",
            "Epoch 120/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0637 - accuracy: 0.9966 - val_loss: 0.0338 - val_accuracy: 0.9973\n",
            "Epoch 121/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0642 - accuracy: 0.9967 - val_loss: 0.0336 - val_accuracy: 0.9973\n",
            "Epoch 122/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0641 - accuracy: 0.9967 - val_loss: 0.0334 - val_accuracy: 0.9973\n",
            "Epoch 123/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0633 - accuracy: 0.9968 - val_loss: 0.0337 - val_accuracy: 0.9973\n",
            "Epoch 124/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0612 - accuracy: 0.9969 - val_loss: 0.0333 - val_accuracy: 0.9973\n",
            "Epoch 125/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0642 - accuracy: 0.9968 - val_loss: 0.0335 - val_accuracy: 0.9973\n",
            "Epoch 126/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0629 - accuracy: 0.9968 - val_loss: 0.0328 - val_accuracy: 0.9974\n",
            "Epoch 127/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0647 - accuracy: 0.9966 - val_loss: 0.0329 - val_accuracy: 0.9973\n",
            "Epoch 128/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0632 - accuracy: 0.9968 - val_loss: 0.0327 - val_accuracy: 0.9973\n",
            "Epoch 129/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0624 - accuracy: 0.9969 - val_loss: 0.0325 - val_accuracy: 0.9973\n",
            "Epoch 130/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0621 - accuracy: 0.9969 - val_loss: 0.0328 - val_accuracy: 0.9974\n",
            "Epoch 131/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0614 - accuracy: 0.9969 - val_loss: 0.0327 - val_accuracy: 0.9973\n",
            "Epoch 132/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0615 - accuracy: 0.9968 - val_loss: 0.0323 - val_accuracy: 0.9973\n",
            "Epoch 133/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0629 - accuracy: 0.9968 - val_loss: 0.0323 - val_accuracy: 0.9974\n",
            "Epoch 134/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0623 - accuracy: 0.9967 - val_loss: 0.0321 - val_accuracy: 0.9973\n",
            "Epoch 135/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0632 - accuracy: 0.9968 - val_loss: 0.0321 - val_accuracy: 0.9974\n",
            "Epoch 136/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0613 - accuracy: 0.9969 - val_loss: 0.0320 - val_accuracy: 0.9974\n",
            "Epoch 137/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0620 - accuracy: 0.9969 - val_loss: 0.0318 - val_accuracy: 0.9972\n",
            "Epoch 138/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0615 - accuracy: 0.9969 - val_loss: 0.0315 - val_accuracy: 0.9975\n",
            "Epoch 139/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0616 - accuracy: 0.9969 - val_loss: 0.0316 - val_accuracy: 0.9974\n",
            "Epoch 140/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0609 - accuracy: 0.9970 - val_loss: 0.0315 - val_accuracy: 0.9974\n",
            "Epoch 141/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0616 - accuracy: 0.9969 - val_loss: 0.0311 - val_accuracy: 0.9974\n",
            "Epoch 142/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0605 - accuracy: 0.9969 - val_loss: 0.0313 - val_accuracy: 0.9975\n",
            "Epoch 143/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0630 - accuracy: 0.9968 - val_loss: 0.0312 - val_accuracy: 0.9974\n",
            "Epoch 144/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0598 - accuracy: 0.9970 - val_loss: 0.0311 - val_accuracy: 0.9975\n",
            "Epoch 145/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0613 - accuracy: 0.9968 - val_loss: 0.0309 - val_accuracy: 0.9974\n",
            "Epoch 146/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0621 - accuracy: 0.9967 - val_loss: 0.0309 - val_accuracy: 0.9974\n",
            "Epoch 147/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0605 - accuracy: 0.9968 - val_loss: 0.0306 - val_accuracy: 0.9975\n",
            "Epoch 148/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0599 - accuracy: 0.9969 - val_loss: 0.0307 - val_accuracy: 0.9975\n",
            "Epoch 149/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0590 - accuracy: 0.9970 - val_loss: 0.0306 - val_accuracy: 0.9974\n",
            "Epoch 150/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0618 - accuracy: 0.9969 - val_loss: 0.0306 - val_accuracy: 0.9975\n",
            "Epoch 151/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0597 - accuracy: 0.9969 - val_loss: 0.0307 - val_accuracy: 0.9975\n",
            "Epoch 152/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0596 - accuracy: 0.9970 - val_loss: 0.0304 - val_accuracy: 0.9975\n",
            "Epoch 153/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0599 - accuracy: 0.9970 - val_loss: 0.0304 - val_accuracy: 0.9975\n",
            "Epoch 154/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0592 - accuracy: 0.9970 - val_loss: 0.0301 - val_accuracy: 0.9975\n",
            "Epoch 155/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0591 - accuracy: 0.9970 - val_loss: 0.0302 - val_accuracy: 0.9975\n",
            "Epoch 156/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0587 - accuracy: 0.9969 - val_loss: 0.0305 - val_accuracy: 0.9975\n",
            "Epoch 157/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0589 - accuracy: 0.9969 - val_loss: 0.0299 - val_accuracy: 0.9975\n",
            "Epoch 158/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0584 - accuracy: 0.9971 - val_loss: 0.0301 - val_accuracy: 0.9975\n",
            "Epoch 159/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0594 - accuracy: 0.9969 - val_loss: 0.0301 - val_accuracy: 0.9975\n",
            "Epoch 160/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0581 - accuracy: 0.9970 - val_loss: 0.0299 - val_accuracy: 0.9974\n",
            "Epoch 161/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0592 - accuracy: 0.9970 - val_loss: 0.0300 - val_accuracy: 0.9975\n",
            "Epoch 162/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0577 - accuracy: 0.9970 - val_loss: 0.0298 - val_accuracy: 0.9975\n",
            "Epoch 163/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0600 - accuracy: 0.9969 - val_loss: 0.0298 - val_accuracy: 0.9974\n",
            "Epoch 164/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0591 - accuracy: 0.9970 - val_loss: 0.0299 - val_accuracy: 0.9975\n",
            "Epoch 165/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0572 - accuracy: 0.9971 - val_loss: 0.0299 - val_accuracy: 0.9975\n",
            "Epoch 166/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0581 - accuracy: 0.9969 - val_loss: 0.0299 - val_accuracy: 0.9974\n",
            "Epoch 167/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0567 - accuracy: 0.9971 - val_loss: 0.0296 - val_accuracy: 0.9975\n",
            "Epoch 168/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0587 - accuracy: 0.9970 - val_loss: 0.0300 - val_accuracy: 0.9974\n",
            "Epoch 169/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0584 - accuracy: 0.9970 - val_loss: 0.0294 - val_accuracy: 0.9975\n",
            "Epoch 170/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0582 - accuracy: 0.9971 - val_loss: 0.0293 - val_accuracy: 0.9975\n",
            "Epoch 171/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0576 - accuracy: 0.9969 - val_loss: 0.0294 - val_accuracy: 0.9976\n",
            "Epoch 172/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0598 - accuracy: 0.9969 - val_loss: 0.0294 - val_accuracy: 0.9975\n",
            "Epoch 173/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0575 - accuracy: 0.9970 - val_loss: 0.0295 - val_accuracy: 0.9974\n",
            "Epoch 174/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0573 - accuracy: 0.9970 - val_loss: 0.0293 - val_accuracy: 0.9976\n",
            "Epoch 175/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0579 - accuracy: 0.9970 - val_loss: 0.0289 - val_accuracy: 0.9974\n",
            "Epoch 176/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0576 - accuracy: 0.9970 - val_loss: 0.0293 - val_accuracy: 0.9976\n",
            "Epoch 177/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0559 - accuracy: 0.9971 - val_loss: 0.0292 - val_accuracy: 0.9975\n",
            "Epoch 178/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0579 - accuracy: 0.9970 - val_loss: 0.0293 - val_accuracy: 0.9975\n",
            "Epoch 179/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0562 - accuracy: 0.9971 - val_loss: 0.0290 - val_accuracy: 0.9976\n",
            "Epoch 180/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0573 - accuracy: 0.9971 - val_loss: 0.0285 - val_accuracy: 0.9975\n",
            "Epoch 181/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0553 - accuracy: 0.9972 - val_loss: 0.0287 - val_accuracy: 0.9975\n",
            "Epoch 182/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0572 - accuracy: 0.9971 - val_loss: 0.0288 - val_accuracy: 0.9976\n",
            "Epoch 183/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0571 - accuracy: 0.9971 - val_loss: 0.0288 - val_accuracy: 0.9976\n",
            "Epoch 184/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0569 - accuracy: 0.9969 - val_loss: 0.0287 - val_accuracy: 0.9976\n",
            "Epoch 185/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0579 - accuracy: 0.9970 - val_loss: 0.0286 - val_accuracy: 0.9975\n",
            "Epoch 186/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0563 - accuracy: 0.9971 - val_loss: 0.0283 - val_accuracy: 0.9976\n",
            "Epoch 187/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0555 - accuracy: 0.9970 - val_loss: 0.0285 - val_accuracy: 0.9976\n",
            "Epoch 188/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0562 - accuracy: 0.9971 - val_loss: 0.0286 - val_accuracy: 0.9975\n",
            "Epoch 189/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0569 - accuracy: 0.9969 - val_loss: 0.0284 - val_accuracy: 0.9975\n",
            "Epoch 190/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0563 - accuracy: 0.9971 - val_loss: 0.0285 - val_accuracy: 0.9976\n",
            "Epoch 191/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0568 - accuracy: 0.9970 - val_loss: 0.0286 - val_accuracy: 0.9975\n",
            "Epoch 192/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0571 - accuracy: 0.9971 - val_loss: 0.0284 - val_accuracy: 0.9976\n",
            "Epoch 193/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0585 - accuracy: 0.9970 - val_loss: 0.0282 - val_accuracy: 0.9976\n",
            "Epoch 194/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0568 - accuracy: 0.9969 - val_loss: 0.0281 - val_accuracy: 0.9976\n",
            "Epoch 195/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0554 - accuracy: 0.9971 - val_loss: 0.0279 - val_accuracy: 0.9976\n",
            "Epoch 196/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0562 - accuracy: 0.9970 - val_loss: 0.0281 - val_accuracy: 0.9976\n",
            "Epoch 197/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0561 - accuracy: 0.9971 - val_loss: 0.0281 - val_accuracy: 0.9976\n",
            "Epoch 198/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0548 - accuracy: 0.9971 - val_loss: 0.0279 - val_accuracy: 0.9976\n",
            "Epoch 199/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0564 - accuracy: 0.9970 - val_loss: 0.0281 - val_accuracy: 0.9975\n",
            "Epoch 200/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0559 - accuracy: 0.9970 - val_loss: 0.0281 - val_accuracy: 0.9975\n",
            "Epoch 201/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0552 - accuracy: 0.9972 - val_loss: 0.0281 - val_accuracy: 0.9976\n",
            "Epoch 202/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0555 - accuracy: 0.9969 - val_loss: 0.0281 - val_accuracy: 0.9975\n",
            "Epoch 203/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0564 - accuracy: 0.9971 - val_loss: 0.0280 - val_accuracy: 0.9975\n",
            "Epoch 204/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0564 - accuracy: 0.9970 - val_loss: 0.0278 - val_accuracy: 0.9975\n",
            "Epoch 205/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0551 - accuracy: 0.9971 - val_loss: 0.0280 - val_accuracy: 0.9975\n",
            "Epoch 206/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0540 - accuracy: 0.9972 - val_loss: 0.0279 - val_accuracy: 0.9975\n",
            "Epoch 207/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0559 - accuracy: 0.9970 - val_loss: 0.0278 - val_accuracy: 0.9977\n",
            "Epoch 208/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0560 - accuracy: 0.9972 - val_loss: 0.0279 - val_accuracy: 0.9975\n",
            "Epoch 209/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0571 - accuracy: 0.9970 - val_loss: 0.0276 - val_accuracy: 0.9976\n",
            "Epoch 210/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0544 - accuracy: 0.9970 - val_loss: 0.0280 - val_accuracy: 0.9976\n",
            "Epoch 211/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0556 - accuracy: 0.9970 - val_loss: 0.0277 - val_accuracy: 0.9975\n",
            "Epoch 212/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0545 - accuracy: 0.9970 - val_loss: 0.0281 - val_accuracy: 0.9976\n",
            "Epoch 213/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0552 - accuracy: 0.9971 - val_loss: 0.0276 - val_accuracy: 0.9975\n",
            "Epoch 214/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0541 - accuracy: 0.9971 - val_loss: 0.0277 - val_accuracy: 0.9976\n",
            "Epoch 215/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0564 - accuracy: 0.9971 - val_loss: 0.0278 - val_accuracy: 0.9975\n",
            "Epoch 216/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0547 - accuracy: 0.9971 - val_loss: 0.0275 - val_accuracy: 0.9976\n",
            "Epoch 217/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0556 - accuracy: 0.9971 - val_loss: 0.0275 - val_accuracy: 0.9975\n",
            "Epoch 218/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0567 - accuracy: 0.9969 - val_loss: 0.0276 - val_accuracy: 0.9975\n",
            "Epoch 219/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0543 - accuracy: 0.9971 - val_loss: 0.0277 - val_accuracy: 0.9976\n",
            "Epoch 220/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0561 - accuracy: 0.9971 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 221/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0544 - accuracy: 0.9971 - val_loss: 0.0273 - val_accuracy: 0.9976\n",
            "Epoch 222/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0545 - accuracy: 0.9971 - val_loss: 0.0275 - val_accuracy: 0.9976\n",
            "Epoch 223/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0563 - accuracy: 0.9969 - val_loss: 0.0276 - val_accuracy: 0.9975\n",
            "Epoch 224/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0536 - accuracy: 0.9971 - val_loss: 0.0276 - val_accuracy: 0.9976\n",
            "Epoch 225/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0545 - accuracy: 0.9970 - val_loss: 0.0276 - val_accuracy: 0.9976\n",
            "Epoch 226/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0533 - accuracy: 0.9972 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 227/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0563 - accuracy: 0.9969 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 228/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0553 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9977\n",
            "Epoch 229/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0557 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9976\n",
            "Epoch 230/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0556 - accuracy: 0.9971 - val_loss: 0.0275 - val_accuracy: 0.9976\n",
            "Epoch 231/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9970 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 232/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0551 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 233/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0532 - accuracy: 0.9972 - val_loss: 0.0276 - val_accuracy: 0.9977\n",
            "Epoch 234/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0539 - accuracy: 0.9972 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 235/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0558 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 236/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0549 - accuracy: 0.9971 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 237/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0548 - accuracy: 0.9971 - val_loss: 0.0278 - val_accuracy: 0.9976\n",
            "Epoch 238/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0551 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 239/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0551 - accuracy: 0.9969 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 240/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0539 - accuracy: 0.9971 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 241/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0545 - accuracy: 0.9972 - val_loss: 0.0276 - val_accuracy: 0.9975\n",
            "Epoch 242/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0515 - accuracy: 0.9972 - val_loss: 0.0271 - val_accuracy: 0.9975\n",
            "Epoch 243/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0541 - accuracy: 0.9972 - val_loss: 0.0271 - val_accuracy: 0.9977\n",
            "Epoch 244/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0544 - accuracy: 0.9971 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 245/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0525 - accuracy: 0.9972 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 246/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0557 - accuracy: 0.9970 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 247/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0543 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9975\n",
            "Epoch 248/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0535 - accuracy: 0.9971 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 249/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0540 - accuracy: 0.9971 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 250/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0542 - accuracy: 0.9970 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 251/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0566 - accuracy: 0.9969 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 252/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0550 - accuracy: 0.9969 - val_loss: 0.0271 - val_accuracy: 0.9975\n",
            "Epoch 253/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0529 - accuracy: 0.9971 - val_loss: 0.0271 - val_accuracy: 0.9975\n",
            "Epoch 254/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0542 - accuracy: 0.9970 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 255/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0553 - accuracy: 0.9969 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 256/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0528 - accuracy: 0.9971 - val_loss: 0.0275 - val_accuracy: 0.9976\n",
            "Epoch 257/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0549 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 258/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0542 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 259/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0535 - accuracy: 0.9972 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 260/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0535 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9975\n",
            "Epoch 261/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0551 - accuracy: 0.9970 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 262/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0531 - accuracy: 0.9972 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 263/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0537 - accuracy: 0.9971 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 264/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0537 - accuracy: 0.9970 - val_loss: 0.0267 - val_accuracy: 0.9975\n",
            "Epoch 265/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0531 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 266/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0542 - accuracy: 0.9971 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 267/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0524 - accuracy: 0.9972 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 268/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0530 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9977\n",
            "Epoch 269/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0537 - accuracy: 0.9971 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 270/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0521 - accuracy: 0.9972 - val_loss: 0.0271 - val_accuracy: 0.9975\n",
            "Epoch 271/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0552 - accuracy: 0.9969 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 272/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9975\n",
            "Epoch 273/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0527 - accuracy: 0.9971 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 274/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0550 - accuracy: 0.9969 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 275/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0548 - accuracy: 0.9970 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 276/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0548 - accuracy: 0.9969 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 277/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0541 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 278/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0540 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 279/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0545 - accuracy: 0.9971 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 280/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0543 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9975\n",
            "Epoch 281/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0526 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9975\n",
            "Epoch 282/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0539 - accuracy: 0.9971 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 283/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0521 - accuracy: 0.9971 - val_loss: 0.0271 - val_accuracy: 0.9975\n",
            "Epoch 284/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0531 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 285/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0550 - accuracy: 0.9970 - val_loss: 0.0264 - val_accuracy: 0.9977\n",
            "Epoch 286/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0532 - accuracy: 0.9971 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 287/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0537 - accuracy: 0.9970 - val_loss: 0.0265 - val_accuracy: 0.9976\n",
            "Epoch 288/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0529 - accuracy: 0.9972 - val_loss: 0.0264 - val_accuracy: 0.9977\n",
            "Epoch 289/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0552 - accuracy: 0.9970 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 290/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0534 - accuracy: 0.9971 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 291/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0540 - accuracy: 0.9971 - val_loss: 0.0270 - val_accuracy: 0.9977\n",
            "Epoch 292/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0530 - accuracy: 0.9971 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 293/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0545 - accuracy: 0.9970 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 294/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9975\n",
            "Epoch 295/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0531 - accuracy: 0.9971 - val_loss: 0.0265 - val_accuracy: 0.9976\n",
            "Epoch 296/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0526 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 297/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0513 - accuracy: 0.9973 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 298/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0541 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 299/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0534 - accuracy: 0.9972 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 300/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9970 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 301/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0536 - accuracy: 0.9971 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 302/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0526 - accuracy: 0.9972 - val_loss: 0.0271 - val_accuracy: 0.9975\n",
            "Epoch 303/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0532 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 304/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0522 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 305/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0529 - accuracy: 0.9972 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 306/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0523 - accuracy: 0.9971 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 307/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0543 - accuracy: 0.9971 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 308/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0519 - accuracy: 0.9972 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 309/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0267 - val_accuracy: 0.9977\n",
            "Epoch 310/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0537 - accuracy: 0.9970 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 311/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0520 - accuracy: 0.9972 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 312/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9970 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 313/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0532 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9977\n",
            "Epoch 314/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0534 - accuracy: 0.9971 - val_loss: 0.0267 - val_accuracy: 0.9977\n",
            "Epoch 315/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0538 - accuracy: 0.9970 - val_loss: 0.0270 - val_accuracy: 0.9975\n",
            "Epoch 316/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0536 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9977\n",
            "Epoch 317/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0530 - accuracy: 0.9971 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 318/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0534 - accuracy: 0.9970 - val_loss: 0.0270 - val_accuracy: 0.9975\n",
            "Epoch 319/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0536 - accuracy: 0.9972 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 320/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0547 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9975\n",
            "Epoch 321/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0523 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9977\n",
            "Epoch 322/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0525 - accuracy: 0.9971 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 323/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0535 - accuracy: 0.9969 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 324/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0542 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9975\n",
            "Epoch 325/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0529 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 326/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0514 - accuracy: 0.9971 - val_loss: 0.0270 - val_accuracy: 0.9975\n",
            "Epoch 327/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0535 - accuracy: 0.9971 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 328/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9971 - val_loss: 0.0267 - val_accuracy: 0.9977\n",
            "Epoch 329/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0532 - accuracy: 0.9970 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 330/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0526 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 331/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0538 - accuracy: 0.9970 - val_loss: 0.0268 - val_accuracy: 0.9975\n",
            "Epoch 332/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0538 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9975\n",
            "Epoch 333/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0540 - accuracy: 0.9969 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 334/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 335/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0535 - accuracy: 0.9971 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 336/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0540 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9975\n",
            "Epoch 337/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0541 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9975\n",
            "Epoch 338/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 339/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0531 - accuracy: 0.9971 - val_loss: 0.0266 - val_accuracy: 0.9976\n",
            "Epoch 340/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0532 - accuracy: 0.9970 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 341/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0521 - accuracy: 0.9971 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 342/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0530 - accuracy: 0.9970 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 343/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0533 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 344/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0523 - accuracy: 0.9970 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 345/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0526 - accuracy: 0.9972 - val_loss: 0.0275 - val_accuracy: 0.9977\n",
            "Epoch 346/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9977\n",
            "Epoch 347/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0530 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 348/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0538 - accuracy: 0.9970 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 349/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0530 - accuracy: 0.9971 - val_loss: 0.0270 - val_accuracy: 0.9977\n",
            "Epoch 350/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0543 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9975\n",
            "Epoch 351/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0529 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9977\n",
            "Epoch 352/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0526 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 353/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0525 - accuracy: 0.9972 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 354/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0520 - accuracy: 0.9971 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 355/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0541 - accuracy: 0.9969 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 356/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9969 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 357/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0534 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 358/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0541 - accuracy: 0.9969 - val_loss: 0.0265 - val_accuracy: 0.9977\n",
            "Epoch 359/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0543 - accuracy: 0.9969 - val_loss: 0.0266 - val_accuracy: 0.9977\n",
            "Epoch 360/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0522 - accuracy: 0.9972 - val_loss: 0.0270 - val_accuracy: 0.9977\n",
            "Epoch 361/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0530 - accuracy: 0.9971 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 362/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0547 - accuracy: 0.9970 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 363/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0528 - accuracy: 0.9971 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 364/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0546 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9977\n",
            "Epoch 365/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0514 - accuracy: 0.9971 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 366/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0532 - accuracy: 0.9970 - val_loss: 0.0268 - val_accuracy: 0.9976\n",
            "Epoch 367/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0534 - accuracy: 0.9970 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 368/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0530 - accuracy: 0.9971 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 369/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0525 - accuracy: 0.9972 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "Epoch 370/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0520 - accuracy: 0.9970 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 371/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0506 - accuracy: 0.9973 - val_loss: 0.0272 - val_accuracy: 0.9975\n",
            "Epoch 372/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0539 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 373/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 374/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0534 - accuracy: 0.9970 - val_loss: 0.0275 - val_accuracy: 0.9976\n",
            "Epoch 375/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0527 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 376/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0530 - accuracy: 0.9971 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 377/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0512 - accuracy: 0.9972 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 378/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 379/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0529 - accuracy: 0.9972 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 380/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0527 - accuracy: 0.9970 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 381/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0530 - accuracy: 0.9970 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 382/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0537 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9977\n",
            "Epoch 383/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0527 - accuracy: 0.9971 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 384/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0530 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 0.9977\n",
            "Epoch 385/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0542 - accuracy: 0.9969 - val_loss: 0.0272 - val_accuracy: 0.9977\n",
            "Epoch 386/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0268 - val_accuracy: 0.9977\n",
            "Epoch 387/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0520 - accuracy: 0.9971 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 388/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0539 - accuracy: 0.9969 - val_loss: 0.0272 - val_accuracy: 0.9977\n",
            "Epoch 389/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0534 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9976\n",
            "Epoch 390/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0529 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9976\n",
            "Epoch 391/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0536 - accuracy: 0.9971 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 392/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 393/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0539 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9976\n",
            "Epoch 394/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0539 - accuracy: 0.9969 - val_loss: 0.0269 - val_accuracy: 0.9977\n",
            "Epoch 395/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9970 - val_loss: 0.0269 - val_accuracy: 0.9977\n",
            "Epoch 396/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0272 - val_accuracy: 0.9977\n",
            "Epoch 397/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0526 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 398/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0542 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 399/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0528 - accuracy: 0.9971 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 400/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0523 - accuracy: 0.9972 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 401/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0516 - accuracy: 0.9970 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 402/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0534 - accuracy: 0.9969 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 403/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0528 - accuracy: 0.9971 - val_loss: 0.0271 - val_accuracy: 0.9977\n",
            "Epoch 404/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0535 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 405/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0524 - accuracy: 0.9971 - val_loss: 0.0273 - val_accuracy: 0.9976\n",
            "Epoch 406/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0535 - accuracy: 0.9971 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 407/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0276 - val_accuracy: 0.9976\n",
            "Epoch 408/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0530 - accuracy: 0.9970 - val_loss: 0.0272 - val_accuracy: 0.9976\n",
            "Epoch 409/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0532 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9977\n",
            "Epoch 410/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9971 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 411/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0541 - accuracy: 0.9970 - val_loss: 0.0270 - val_accuracy: 0.9976\n",
            "Epoch 412/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0530 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9976\n",
            "Epoch 413/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0513 - accuracy: 0.9971 - val_loss: 0.0275 - val_accuracy: 0.9977\n",
            "Epoch 414/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0533 - accuracy: 0.9972 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 415/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0523 - accuracy: 0.9970 - val_loss: 0.0274 - val_accuracy: 0.9977\n",
            "Epoch 416/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0539 - accuracy: 0.9970 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 417/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0535 - accuracy: 0.9970 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 418/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0532 - accuracy: 0.9971 - val_loss: 0.0271 - val_accuracy: 0.9977\n",
            "Epoch 419/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0530 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
            "Epoch 420/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0544 - accuracy: 0.9969 - val_loss: 0.0272 - val_accuracy: 0.9977\n",
            "Epoch 421/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0536 - accuracy: 0.9969 - val_loss: 0.0272 - val_accuracy: 0.9977\n",
            "Epoch 422/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9975\n",
            "Epoch 423/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0532 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9977\n",
            "Epoch 424/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0523 - accuracy: 0.9971 - val_loss: 0.0279 - val_accuracy: 0.9976\n",
            "Epoch 425/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0537 - accuracy: 0.9969 - val_loss: 0.0275 - val_accuracy: 0.9977\n",
            "Epoch 426/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9971 - val_loss: 0.0275 - val_accuracy: 0.9977\n",
            "Epoch 427/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0525 - accuracy: 0.9970 - val_loss: 0.0277 - val_accuracy: 0.9976\n",
            "Epoch 428/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0528 - accuracy: 0.9970 - val_loss: 0.0277 - val_accuracy: 0.9975\n",
            "Epoch 429/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0517 - accuracy: 0.9972 - val_loss: 0.0272 - val_accuracy: 0.9977\n",
            "Epoch 430/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0550 - accuracy: 0.9969 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 431/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0517 - accuracy: 0.9971 - val_loss: 0.0271 - val_accuracy: 0.9977\n",
            "Epoch 432/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0537 - accuracy: 0.9971 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 433/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9971 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 434/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0542 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9976\n",
            "Epoch 435/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0535 - accuracy: 0.9969 - val_loss: 0.0273 - val_accuracy: 0.9976\n",
            "Epoch 436/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0532 - accuracy: 0.9971 - val_loss: 0.0273 - val_accuracy: 0.9976\n",
            "Epoch 437/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0532 - accuracy: 0.9971 - val_loss: 0.0277 - val_accuracy: 0.9975\n",
            "Epoch 438/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0529 - accuracy: 0.9971 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 439/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0532 - accuracy: 0.9970 - val_loss: 0.0277 - val_accuracy: 0.9976\n",
            "Epoch 440/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0537 - accuracy: 0.9972 - val_loss: 0.0274 - val_accuracy: 0.9977\n",
            "Epoch 441/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0544 - accuracy: 0.9969 - val_loss: 0.0275 - val_accuracy: 0.9977\n",
            "Epoch 442/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9977\n",
            "Epoch 443/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0522 - accuracy: 0.9970 - val_loss: 0.0274 - val_accuracy: 0.9977\n",
            "Epoch 444/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0535 - accuracy: 0.9970 - val_loss: 0.0272 - val_accuracy: 0.9977\n",
            "Epoch 445/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0530 - accuracy: 0.9971 - val_loss: 0.0277 - val_accuracy: 0.9976\n",
            "Epoch 446/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9972 - val_loss: 0.0275 - val_accuracy: 0.9977\n",
            "Epoch 447/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0534 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9977\n",
            "Epoch 448/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0551 - accuracy: 0.9969 - val_loss: 0.0275 - val_accuracy: 0.9976\n",
            "Epoch 449/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0526 - accuracy: 0.9971 - val_loss: 0.0276 - val_accuracy: 0.9976\n",
            "Epoch 450/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0529 - accuracy: 0.9970 - val_loss: 0.0276 - val_accuracy: 0.9977\n",
            "Epoch 451/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0550 - accuracy: 0.9969 - val_loss: 0.0281 - val_accuracy: 0.9976\n",
            "Epoch 452/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0519 - accuracy: 0.9972 - val_loss: 0.0277 - val_accuracy: 0.9977\n",
            "Epoch 453/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0538 - accuracy: 0.9971 - val_loss: 0.0273 - val_accuracy: 0.9976\n",
            "Epoch 454/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.0280 - val_accuracy: 0.9977\n",
            "Epoch 455/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0541 - accuracy: 0.9970 - val_loss: 0.0283 - val_accuracy: 0.9975\n",
            "Epoch 456/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0541 - accuracy: 0.9970 - val_loss: 0.0279 - val_accuracy: 0.9975\n",
            "Epoch 457/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0538 - accuracy: 0.9971 - val_loss: 0.0278 - val_accuracy: 0.9977\n",
            "Epoch 458/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0541 - accuracy: 0.9970 - val_loss: 0.0278 - val_accuracy: 0.9976\n",
            "Epoch 459/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0551 - accuracy: 0.9969 - val_loss: 0.0277 - val_accuracy: 0.9977\n",
            "Epoch 460/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0532 - accuracy: 0.9970 - val_loss: 0.0276 - val_accuracy: 0.9976\n",
            "Epoch 461/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9969 - val_loss: 0.0277 - val_accuracy: 0.9977\n",
            "Epoch 462/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0527 - accuracy: 0.9970 - val_loss: 0.0275 - val_accuracy: 0.9976\n",
            "Epoch 463/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0536 - accuracy: 0.9970 - val_loss: 0.0276 - val_accuracy: 0.9976\n",
            "Epoch 464/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0528 - accuracy: 0.9971 - val_loss: 0.0278 - val_accuracy: 0.9977\n",
            "Epoch 465/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0551 - accuracy: 0.9969 - val_loss: 0.0280 - val_accuracy: 0.9976\n",
            "Epoch 466/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0529 - accuracy: 0.9971 - val_loss: 0.0277 - val_accuracy: 0.9976\n",
            "Epoch 467/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0542 - accuracy: 0.9970 - val_loss: 0.0277 - val_accuracy: 0.9976\n",
            "Epoch 468/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0536 - accuracy: 0.9968 - val_loss: 0.0274 - val_accuracy: 0.9977\n",
            "Epoch 469/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0544 - accuracy: 0.9971 - val_loss: 0.0280 - val_accuracy: 0.9976\n",
            "Epoch 470/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0553 - accuracy: 0.9968 - val_loss: 0.0277 - val_accuracy: 0.9977\n",
            "Epoch 471/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0528 - accuracy: 0.9971 - val_loss: 0.0280 - val_accuracy: 0.9977\n",
            "Epoch 472/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0538 - accuracy: 0.9970 - val_loss: 0.0279 - val_accuracy: 0.9975\n",
            "Epoch 473/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0546 - accuracy: 0.9970 - val_loss: 0.0281 - val_accuracy: 0.9975\n",
            "Epoch 474/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0526 - accuracy: 0.9970 - val_loss: 0.0278 - val_accuracy: 0.9977\n",
            "Epoch 475/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0545 - accuracy: 0.9970 - val_loss: 0.0276 - val_accuracy: 0.9977\n",
            "Epoch 476/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0549 - accuracy: 0.9967 - val_loss: 0.0274 - val_accuracy: 0.9976\n",
            "Epoch 477/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0543 - accuracy: 0.9971 - val_loss: 0.0275 - val_accuracy: 0.9976\n",
            "Epoch 478/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0540 - accuracy: 0.9970 - val_loss: 0.0280 - val_accuracy: 0.9976\n",
            "Epoch 479/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0528 - accuracy: 0.9971 - val_loss: 0.0280 - val_accuracy: 0.9976\n",
            "Epoch 480/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0534 - accuracy: 0.9971 - val_loss: 0.0278 - val_accuracy: 0.9976\n",
            "Epoch 481/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0539 - accuracy: 0.9970 - val_loss: 0.0275 - val_accuracy: 0.9977\n",
            "Epoch 482/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0531 - accuracy: 0.9971 - val_loss: 0.0281 - val_accuracy: 0.9977\n",
            "Epoch 483/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0535 - accuracy: 0.9970 - val_loss: 0.0280 - val_accuracy: 0.9977\n",
            "Epoch 484/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0539 - accuracy: 0.9970 - val_loss: 0.0277 - val_accuracy: 0.9976\n",
            "Epoch 485/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0528 - accuracy: 0.9971 - val_loss: 0.0280 - val_accuracy: 0.9976\n",
            "Epoch 486/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0555 - accuracy: 0.9970 - val_loss: 0.0280 - val_accuracy: 0.9977\n",
            "Epoch 487/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9971 - val_loss: 0.0279 - val_accuracy: 0.9976\n",
            "Epoch 488/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0546 - accuracy: 0.9969 - val_loss: 0.0283 - val_accuracy: 0.9976\n",
            "Epoch 489/500\n",
            "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0542 - accuracy: 0.9970 - val_loss: 0.0278 - val_accuracy: 0.9976\n",
            "Epoch 490/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0544 - accuracy: 0.9970 - val_loss: 0.0282 - val_accuracy: 0.9977\n",
            "Epoch 491/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0528 - accuracy: 0.9971 - val_loss: 0.0278 - val_accuracy: 0.9977\n",
            "Epoch 492/500\n",
            "1505/1505 [==============================] - 8s 6ms/step - loss: 0.0547 - accuracy: 0.9969 - val_loss: 0.0280 - val_accuracy: 0.9976\n",
            "Epoch 493/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0539 - accuracy: 0.9969 - val_loss: 0.0285 - val_accuracy: 0.9976\n",
            "Epoch 494/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0559 - accuracy: 0.9969 - val_loss: 0.0281 - val_accuracy: 0.9977\n",
            "Epoch 495/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0544 - accuracy: 0.9970 - val_loss: 0.0281 - val_accuracy: 0.9976\n",
            "Epoch 496/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0541 - accuracy: 0.9970 - val_loss: 0.0281 - val_accuracy: 0.9976\n",
            "Epoch 497/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0537 - accuracy: 0.9970 - val_loss: 0.0281 - val_accuracy: 0.9977\n",
            "Epoch 498/500\n",
            "1505/1505 [==============================] - 9s 6ms/step - loss: 0.0533 - accuracy: 0.9971 - val_loss: 0.0281 - val_accuracy: 0.9977\n",
            "Epoch 499/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9971 - val_loss: 0.0280 - val_accuracy: 0.9976\n",
            "Epoch 500/500\n",
            "1505/1505 [==============================] - 8s 5ms/step - loss: 0.0543 - accuracy: 0.9970 - val_loss: 0.0281 - val_accuracy: 0.9977\n",
            "Test loss: 0.028091810643672943\n",
            "Test accuracy: 0.9976751804351807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7C5VYwVlIFf",
        "outputId": "53ba0054-4440-4ca0-8f90-85e051df4f1a"
      },
      "source": [
        "predictions = model.predict(X_train)\n",
        "predictions = (predictions > 0.5)\n",
        "\n",
        "print(confusion_matrix(Y_train, predictions))\n",
        "print(classification_report(Y_train, predictions))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[728346    206]\n",
            " [  1363  40457]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    728552\n",
            "           1       0.99      0.97      0.98     41820\n",
            "\n",
            "    accuracy                           1.00    770372\n",
            "   macro avg       1.00      0.98      0.99    770372\n",
            "weighted avg       1.00      1.00      1.00    770372\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mih7TrvxlH_8",
        "outputId": "bd9bed80-f114-4129-ae8a-25ad8d1487f4"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions = (predictions > 0.50)\n",
        "\n",
        "print(confusion_matrix(Y_test, predictions))\n",
        "print(classification_report(Y_test, predictions))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[80922    28]\n",
            " [  171  4476]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     80950\n",
            "           1       0.99      0.96      0.98      4647\n",
            "\n",
            "    accuracy                           1.00     85597\n",
            "   macro avg       1.00      0.98      0.99     85597\n",
            "weighted avg       1.00      1.00      1.00     85597\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKIw_0J7UwE-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "1983de9e-48f4-45a5-a092-4163e73c737f"
      },
      "source": [
        "fpr, tpr,z = metrics.roc_curve(Y_test, Y_pred)\n",
        "auc = metrics.auc(fpr,tpr)\n",
        "print(auc)\n",
        "print(fpr)\n",
        "print(tpr)\n",
        " \n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9761806676765699\n",
            "[0.         0.00696726 1.        ]\n",
            "[0.        0.9593286 1.       ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'True Positive Rate')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM7h0yxXUwCa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "475d49ed-ec80-4d4d-f5ec-ceefb48c2fd6"
      },
      "source": [
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "probs = model.predict(X_test)\n",
        "preds = probs\n",
        "precision, recall, threshold = precision_recall_curve(Y_test, preds)\n",
        "\n",
        "plt.title(\"Precision-Recall vs Threshold Chart\")\n",
        "plt.plot(threshold, precision[: -1], \"b--\", label=\"Precision\")\n",
        "plt.plot(threshold, recall[: -1], \"r--\", label=\"Recall\")\n",
        "plt.ylabel(\"Precision, Recall\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.ylim([0,1]) \n",
        "\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QepF5NCneJeq",
        "outputId": "08a2e476-7c8c-44a2-c6db-8e9b96f54ea1"
      },
      "source": [
        "threshold = 0.5\n",
        "pred = np.where(model.predict(X_test) >= threshold, 1, 0)\n",
        "labels = [1, 0]\n",
        "con_mat2 = confusion_matrix(Y_test, pred, labels = labels )\n",
        "print(con_mat2)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "actual = Y_test\n",
        "predicted = pred\n",
        "print ('Accuracy Score :',accuracy_score(actual, predicted)) \n",
        "print ('Report : ')\n",
        "print (classification_report(actual, predicted))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4476   171]\n",
            " [   28 80922]]\n",
            "Accuracy Score : 0.9976751521665479\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     80950\n",
            "           1       0.99      0.96      0.98      4647\n",
            "\n",
            "    accuracy                           1.00     85597\n",
            "   macro avg       1.00      0.98      0.99     85597\n",
            "weighted avg       1.00      1.00      1.00     85597\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sis0EbrGvk9g"
      },
      "source": [
        "XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLwgnZLneJZL"
      },
      "source": [
        "from xgboost import XGBClassifier\r\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GaAYa6tPX2Y",
        "outputId": "b345c5a0-ee51-4c16-f0cc-b9751b332c82"
      },
      "source": [
        "modelXGB = XGBClassifier(n_estimators=200, \r\n",
        "              max_depth=10,scale_pos_weight=int(728552/(41820*10))) \r\n",
        "modelXGB.fit(X_train, Y_train)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
              "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXMM_XUHPX7b",
        "outputId": "06176bfc-8bbb-4b1a-a331-eb677c676de7"
      },
      "source": [
        "predictions = modelXGB.predict(X_train)\r\n",
        "print(confusion_matrix(Y_train, predictions))\r\n",
        "print(classification_report(Y_train, predictions))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[728552      0]\n",
            " [    10  41810]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    728552\n",
            "           1       1.00      1.00      1.00     41820\n",
            "\n",
            "    accuracy                           1.00    770372\n",
            "   macro avg       1.00      1.00      1.00    770372\n",
            "weighted avg       1.00      1.00      1.00    770372\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swkCsQaSPYAA",
        "outputId": "853fd371-aa36-434b-f969-2556d3fc35d9"
      },
      "source": [
        "predictions = modelXGB.predict(X_test)\r\n",
        "print(confusion_matrix(Y_test, predictions))\r\n",
        "print(classification_report(Y_test, predictions))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[80950     0]\n",
            " [   97  4550]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     80950\n",
            "           1       1.00      0.98      0.99      4647\n",
            "\n",
            "    accuracy                           1.00     85597\n",
            "   macro avg       1.00      0.99      0.99     85597\n",
            "weighted avg       1.00      1.00      1.00     85597\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVqjd8NpPYEm"
      },
      "source": [
        "#Saved weights\r\n",
        "import pickle\r\n",
        "file_name = \"/content/gdrive/My Drive/Colab Notebooks/Loan_default/xgb_reg.pkl\"\r\n",
        "\r\n",
        "# save\r\n",
        "#pickle.dump(modelXGB, open(file_name, \"wb\"))\r\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hL3OApAPYI7"
      },
      "source": [
        "\r\n",
        "# load\r\n",
        "xgb_model_loaded = pickle.load(open(file_name, \"rb\"))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaqLSkC5uP48",
        "outputId": "72257a28-816d-4721-a025-ec5602cce152"
      },
      "source": [
        "predictions = xgb_model_loaded.predict(X_train)\r\n",
        "print(confusion_matrix(Y_train, predictions))\r\n",
        "print(classification_report(Y_train, predictions))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[728552      0]\n",
            " [    88  41732]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    728552\n",
            "           1       1.00      1.00      1.00     41820\n",
            "\n",
            "    accuracy                           1.00    770372\n",
            "   macro avg       1.00      1.00      1.00    770372\n",
            "weighted avg       1.00      1.00      1.00    770372\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcxPMfg9PYNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127c2217-8834-4509-cca8-f821e12c7e81"
      },
      "source": [
        "predictions = xgb_model_loaded.predict(X_test)\r\n",
        "print(confusion_matrix(Y_test, predictions))\r\n",
        "print(classification_report(Y_test, predictions))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[80950     0]\n",
            " [   12  4635]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     80950\n",
            "           1       1.00      1.00      1.00      4647\n",
            "\n",
            "    accuracy                           1.00     85597\n",
            "   macro avg       1.00      1.00      1.00     85597\n",
            "weighted avg       1.00      1.00      1.00     85597\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyNrfYzVVpGU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTJzY9wMVpLb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKOF2nuDVpQq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXoRZVVrUv-q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}